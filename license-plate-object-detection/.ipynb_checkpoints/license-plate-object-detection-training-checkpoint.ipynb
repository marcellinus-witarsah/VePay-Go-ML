{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df248e05",
   "metadata": {},
   "source": [
    "# License Plate Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b3950",
   "metadata": {},
   "source": [
    "## Installation for Using NVIDIA GPU Device\n",
    "License Plate Object Detection is the part of our Deep Learning Pipeline where we need to identify Region of Interest of the license plate that we want to recognize. Our Object Detection model will be using a ***YOLOv5*** method which has been created by ***ultralytics***. All Credits goes to every people who are involve in bringing YOLOv5 Method to live. The code can be accessed using this link https://github.com/ultralytics/yolov5.\n",
    "\n",
    "The training of the data will be using NVIDIA GeForce GTX 1660 Ti device. But there are some things that we need to prepare for this project such as:\n",
    "1. Installing CUDA Toolkit version 10.2 (use this [link](https://developer.nvidia.com/cuda-10.2-download-archive) for downloading it)\n",
    "2. Installing CuDNN version 8.3.0 (or pick other version that is compatible with CUDA Toolkit version, check this [link](https://developer.nvidia.com/rdp/cudnn-archive) for further information)\n",
    "3. Installing NVIDIA driver from this [link](https://www.nvidia.com/download/index.aspx) and choose the driver based on your GPU device name and type.\n",
    "4. Installing Visual Studio 2019 using this [link](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=community&rel=16&utm_medium=microsoft&utm_source=docs.microsoft.com&utm_campaign=download+from+relnotes&utm_content=vs2019ga+button) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebacca",
   "metadata": {},
   "source": [
    "## Setting Up Environment\n",
    "Python environment can be created using [anaconda](https://www.anaconda.com/) or [pipenv](https://pipenv.pypa.io/en/latest/) package by Python. In this project, pipenv is a tool that has been chosen for setting up environment. For starting things off, download the any Python version and then run ***pip install pipenv*** for installing pipenv package. Then setting up the environment at your project directory folder by running ***python -m pipenv --python 3.8.6***. Then you want to access or activate the environment using ***python -m pipenv shell***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b6d18",
   "metadata": {},
   "source": [
    "Next, we need to install libaries to enable pytorch to access GPU by installing python packages by using this command\n",
    "***pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html***\n",
    "\n",
    "This command can be run in the jupyter notebook or in the command line (***make sure to run the command in the python environment we just created***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bb187ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu102 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (1.9.0+cu102)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu102 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (0.10.0+cu102)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from torch==1.9.0+cu102) (4.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from torchvision==0.10.0+cu102) (1.22.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from torchvision==0.10.0+cu102) (9.1.0)\n"
     ]
    }
   ],
   "source": [
    "# # run this command if it takes too long just run it on the command prompt, inside the python environment\n",
    "!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f22eadcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0+cu102 (NVIDIA GeForce GTX 1660 Ti)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63317b",
   "metadata": {},
   "source": [
    "## Clone Repository\n",
    "Clone yolov5 repository by ***ultralytics*** from this link https://github.com/ultralytics/yolov5\n",
    "\n",
    "***Make sure that git has already installed in your computer and enabled to be executed from any file directory*** (set git into the environment variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f61b16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "yolov5 already exists and up to date\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 4)) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 5)) (1.22.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 6)) (4.5.5.64)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 7)) (9.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 9)) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 10)) (1.8.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 11)) (1.9.0+cu102)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 12)) (0.10.0+cu102)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 13)) (4.64.0)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 16)) (2.9.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 20)) (1.4.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
      "Requirement already satisfied: thop in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 37)) (0.0.31.post2005241907)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.33.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.5.30)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tqdm>=4.41.0->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.20.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.46.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.6.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (62.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2022.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: certifi==2021.5.30 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2021.5.30)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.22.3)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3==1.26.6 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.26.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (4.5.5.64)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (4.64.0)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2.27.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (3.5.2)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (9.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: wget in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (0.20.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib->roboflow) (4.33.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests->roboflow) (2.0.12)\n",
      "Installing collected packages: pyparsing\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "Successfully installed pyparsing-2.4.7\n"
     ]
    }
   ],
   "source": [
    "# clone the repo from this link 'https://github.com/ultralytics/yolov5.git'\n",
    "git_https = 'https://github.com/ultralytics/yolov5.git'\n",
    "folder_name = 'yolov5'\n",
    "if not os.path.exists(os.path.join(os.getcwd(), folder_name)):\n",
    "    !git clone {git_https}\n",
    "else:\n",
    "    !cd yolov5 && git pull\n",
    "    print(folder_name, 'already exists and up to date')\n",
    "\n",
    "# install requirements of yolov5\n",
    "!cd yolov5 && pip install -r requirements.txt\n",
    "# install roboflow for data pulling\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438aad67",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "After collecting our data, we will be using roboflow (can be accessed from this [link](https://roboflow.com/)) which is a tool for anotating region of interest. In this case, the region of interest is license plate. After anotating, we can export into any form of a dataset that will be accepted by our model. We can export it manually or using an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46e687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling costum-data created from roboflow website using API\n",
    "####################################TEMPLATE EXAMPLE#########################################\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"***************\")\n",
    "# project = rf.workspace(\"augmented-startups\").project(\"vehicle-registration-plates-trudk\")\n",
    "# dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af661e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exists\n",
      "location of dataset =  C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\datasets\\Car-License-Plate-1\n"
     ]
    }
   ],
   "source": [
    "# Setting up location for the dataset\n",
    "DATASET_PARENT_FOLDER = os.path.join(os.getcwd(), 'datasets')\n",
    "DATASET_FOLDER_NAME = 'Car-License-Plate-1' # filled later becase the dataset is still being collected\n",
    "DATASET_LOCATION = os.path.join(DATASET_PARENT_FOLDER, DATASET_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(DATASET_LOCATION):\n",
    "    print(\"dataset doesn't exists\")\n",
    "else:\n",
    "    print(\"dataset already exists\")\n",
    "    \n",
    "\n",
    "print('location of dataset = ', DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943beedf",
   "metadata": {},
   "source": [
    "Checking up the data.yaml inside the **DATASET_LOCATION** because the object detection API that is used needs it to find information where we put our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8212ac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = ../datasets/Car-License-Plate-1\n",
      "train = train/images\n",
      "val = valid/images\n",
      "nc = 1\n",
      "names = ['Plate']\n",
      "num of classes =  1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# take a look inside the data.yaml file\n",
    "import yaml\n",
    "with open(os.path.join(DATASET_LOCATION, \"data.yaml\"), \"r\") as stream:\n",
    "    try:\n",
    "        content = yaml.safe_load(stream) \n",
    "        # print the content of data.yaml file\n",
    "        # we need to change the train and val path\n",
    "        for key, vals in content.items():\n",
    "            print(key, '=', vals)\n",
    "            \n",
    "        num_classes= content['nc']\n",
    "        print('num of classes = ', num_classes)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# number of classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590f930",
   "metadata": {},
   "source": [
    "## Configure Yolov5 Model\n",
    "We can do this configuring the .yaml file of that model that has been provided inside the yolov5 repo that we clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35d9222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## Yolo V5 default version ##############################\n",
      "yolov5l.yaml\n",
      "yolov5m.yaml\n",
      "yolov5n.yaml\n",
      "yolov5s.yaml\n",
      "yolov5x.yaml\n",
      "\n",
      "############################## Yolo V5 version 6 ##############################\n",
      "yolov5l6.yaml\n",
      "yolov5m6.yaml\n",
      "yolov5n6.yaml\n",
      "yolov5s6.yaml\n",
      "yolov5x6.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_directory = os.path.join(os.getcwd(), 'yolov5', 'models')\n",
    "print('\\n' + 30*'#'+ ' Yolo V5 default version ' + 30*'#')\n",
    "for file in os.listdir(model_directory):\n",
    "    if file.endswith('.yaml'):\n",
    "        print(file)\n",
    "\n",
    "print('\\n' + 30*'#'+ ' Yolo V5 version 6 ' + 30*'#')\n",
    "for file in os.listdir(model_directory+'/hub'):\n",
    "    if file in ['yolov5l6.yaml',  'yolov5m6.yaml', 'yolov5n6.yaml', 'yolov5s6.yaml', 'yolov5x6.yaml']:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011496af",
   "metadata": {},
   "source": [
    "For this project we will be using the Yolo V5 version 6 as our pretrained model for transfer learning the size of the model will be picked based capability of local machine. Don't use heavy model for training if teh hardware capabilty can't keep up with it. There must be a trade off between using **-small size and accuracy model-** or **-big size and high accuracy model-**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2ac8575c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov5l6.yaml\n",
      "{'nc': 80, 'depth_multiple': 1.0, 'width_multiple': 1.0, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5m6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.67, 'width_multiple': 0.75, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5n6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.33, 'width_multiple': 0.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5s6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.33, 'width_multiple': 0.5, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5x6.yaml\n",
      "{'nc': 80, 'depth_multiple': 1.33, 'width_multiple': 1.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "yolov5_v6_yamls = [\n",
    "    'yolov5l6.yaml',  \n",
    "    'yolov5m6.yaml', \n",
    "    'yolov5n6.yaml', \n",
    "    'yolov5s6.yaml', \n",
    "    'yolov5x6.yaml',\n",
    "]\n",
    "\n",
    "for file in os.listdir(os.path.join(model_directory, 'hub')):\n",
    "    if file in yolov5_v6_yamls:\n",
    "        with open(os.path.join(model_directory, 'hub', file), \"r\") as stream:\n",
    "            try:\n",
    "                content = yaml.safe_load(stream)\n",
    "                print(file)\n",
    "                print(content, '\\n')\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1226308",
   "metadata": {},
   "source": [
    "We can just change the ***nc*** into any number according to number of class that we want to predict. In this case, we use ***1*** because we only want to predict one class only which is license plate. Create a file call custom model .yaml by copying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a12d852d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_yolov5l6.yaml already exists\n",
      "custom_yolov5m6.yaml already exists\n",
      "custom_yolov5n6.yaml already exists\n",
      "custom_yolov5s6.yaml already exists\n",
      "custom_yolov5x6.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "# create a new costume .yaml folder to enable the model to predict 1 class only\n",
    "# copy the contents of the .yaml file which is identified by the model's name\n",
    "model_folder = os.path.join(os.getcwd(), 'yolov5', 'models', 'hub')\n",
    "\n",
    "for file in os.listdir(model_directory+'/hub'):\n",
    "    if file in yolov5_v6_yamls:\n",
    "        yaml_ori_path = os.path.join(model_directory, 'hub', file)\n",
    "        custom_yaml_name = 'custom_'+file\n",
    "        custom_yaml_path = os.path.join(model_directory, custom_yaml_name)\n",
    "        \n",
    "        if not os.path.exists(custom_yaml_path):\n",
    "            shutil.copy(yaml_ori_path, custom_yaml_path)\n",
    "            print(yaml_ori_path, 'has been copied to ', custom_yaml_path)\n",
    "        else:\n",
    "            print(custom_yaml_name, 'already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99710519",
   "metadata": {},
   "source": [
    "Edit the .yaml file manually by using a notepad or using other code editor. The result can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6699d7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_yolov5l6.yaml\n",
      "{'nc': 1, 'depth_multiple': 1.0, 'width_multiple': 1.0, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5m6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.67, 'width_multiple': 0.75, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5n6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.33, 'width_multiple': 0.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5s6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.33, 'width_multiple': 0.5, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5x6.yaml\n",
      "{'nc': 1, 'depth_multiple': 1.33, 'width_multiple': 1.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results after editing the .yaml files for model configuration\n",
    "custom_yolov5_v6_yamls = [\n",
    "    'custom_yolov5l6.yaml',  \n",
    "    'custom_yolov5m6.yaml', \n",
    "    'custom_yolov5n6.yaml', \n",
    "    'custom_yolov5s6.yaml', \n",
    "    'custom_yolov5x6.yaml',\n",
    "]\n",
    "\n",
    "for file in os.listdir(model_directory):\n",
    "    if file in custom_yolov5_v6_yamls:\n",
    "        with open(os.path.join(model_directory, file), \"r\") as stream:\n",
    "            try:\n",
    "                content = yaml.safe_load(stream)\n",
    "                print(file)\n",
    "                print(content, '\\n')\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35fc05",
   "metadata": {},
   "source": [
    "## Training Yolov5 Model\n",
    "Since we will be preparing a python script (from /yolov5/train.py) for training, there are some arguments that we need to consider which are:\n",
    "1. ***img:*** define input image size\n",
    "2. ***batch:*** determine batch size\n",
    "3. ***epochs:*** define the number of training epochs. (Note: often, 3000+ are common here!).\n",
    "4. ***data:*** set the path to our yaml file.\n",
    "5. ***cfg:*** specify our model configuration.\n",
    "6. ***weights:*** specify a custom path to weights (if the file doesn't exist the model pretrained weights will be downloaded automatically)\n",
    "7. ***cache:*** cache images for faster training. The default value for this argument is using 'RAM' we can change it to using 'disk' for more storage.\n",
    "8. ***project:*** folder for results\n",
    "9. ***name:*** result names inside the **project** folder\n",
    "10. ***freeze:*** for input how many layers that want to be freezed start from index zero to n-1 layer. For transfer learning we usually freeze the **backbone layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "318ca579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd yolov5 && python train.py --img 640 --batch 32 --epochs 5 --data C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\datasets\\Car-License-Plate-1\\data.yaml --cfg C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\yolov5\\models\\custom_yolov5s6.yaml --weights yolov5s6.pt --workers 3 --cache disk --project train_results --name train --freeze 12\n"
     ]
    }
   ],
   "source": [
    "img = 640\n",
    "batch = 32\n",
    "epochs = 5\n",
    "data = os.path.join(DATASET_LOCATION, 'data.yaml')\n",
    "cfg = os.path.join(model_directory, 'custom_yolov5s6.yaml')\n",
    "weights = 'yolov5s6.pt'\n",
    "workers= 3\n",
    "cache = 'disk'\n",
    "project = 'train_results' \n",
    "name = 'train'\n",
    "freeze = 12\n",
    "\n",
    "command = \"cd yolov5 && python train.py --img {} --batch {} --epochs {} --data {} --cfg {} --weights {} --workers {} --cache {} --project {} --name {} --freeze {}\".\\\n",
    "          format(img, batch, epochs, data, cfg, weights, workers, cache, project, name, freeze)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887e7f1",
   "metadata": {},
   "source": [
    "Run the above command from the command prompt (**inside the python environment that has been created**) so that we can see the training logs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b181142",
   "metadata": {},
   "source": [
    "## Inference using Yolov5 Model\n",
    "Since we will be preparing a python script (from /yolov5/detect.py) for testing, there are some arguments that we need to consider which are:\n",
    "1. ***img:*** define input image size\n",
    "2. ***source:*** input data\n",
    "3. ***conf:*** confidence level treshold\n",
    "4. ***weights:*** specify a custom path from our trained model weights\n",
    "5. ***name:*** file name of the detect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "155900fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd yolov5 && python detect.py --weights  --img  --conf 0.5 --source \n"
     ]
    }
   ],
   "source": [
    "img=''\n",
    "source=''\n",
    "conf=0.5\n",
    "weights=''\n",
    "\n",
    "command = \"cd yolov5 && python detect.py --weights {} --img {} --conf {} --source {}\".\\\n",
    "          format(weights, img, conf, source)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae51da8",
   "metadata": {},
   "source": [
    "## Export Model to TensorflowJS\n",
    "Lastly, we export the model for deployment in Website using Javascript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878eb3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "model_weights_path = input('Please input model path = ')\n",
    "!cd yolov5 && python export.py --weights {model_weights_path} --include tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa4fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c644d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c55467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77f64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f986c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6a315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "license-plate-object-detection (pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

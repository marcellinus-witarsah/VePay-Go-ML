{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df248e05",
   "metadata": {},
   "source": [
    "# License Plate Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b3950",
   "metadata": {},
   "source": [
    "## Installation for Using NVIDIA GPU Device\n",
    "License Plate Object Detection is the part of our Deep Learning Pipeline where we need to identify Region of Interest of the license plate that we want to recognize. Our Object Detection model will be using a ***YOLOv5*** method which has been created by ***ultralytics***. All Credits goes to every people who are involve in bringing YOLOv5 Method to live. The code can be accessed using this link https://github.com/ultralytics/yolov5.\n",
    "\n",
    "The training of the data will be using NVIDIA GeForce GTX 1660 Ti device. But there are some things that we need to prepare for this project such as:\n",
    "1. Installing CUDA Toolkit version 10.2 (use this [link](https://developer.nvidia.com/cuda-10.2-download-archive) for downloading it)\n",
    "2. Installing CuDNN version 8.3.0 (or pick other version that is compatible with CUDA Toolkit version, check this [link](https://developer.nvidia.com/rdp/cudnn-archive) for further information)\n",
    "3. Installing NVIDIA driver from this [link](https://www.nvidia.com/download/index.aspx) and choose the driver based on your GPU device name and type.\n",
    "4. Installing Visual Studio 2019 using this [link](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=community&rel=16&utm_medium=microsoft&utm_source=docs.microsoft.com&utm_campaign=download+from+relnotes&utm_content=vs2019ga+button) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebacca",
   "metadata": {},
   "source": [
    "## Setting Up Environment\n",
    "Python environment can be created using [anaconda](https://www.anaconda.com/) or [pipenv](https://pipenv.pypa.io/en/latest/) package by Python. In this project, pipenv is a tool that has been chosen for setting up environment. For starting things off, download the any Python version and then run ***pip install pipenv*** for installing pipenv package. Then setting up the environment at your project directory folder by running ***python -m pipenv --python 3.8.6***. Then you want to access or activate the environment using ***python -m pipenv shell***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b6d18",
   "metadata": {},
   "source": [
    "Next, we need to install libaries to enable pytorch to access GPU by installing python packages by using this command\n",
    "***pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html***\n",
    "\n",
    "This command can be run in the jupyter notebook or in the command line (***make sure to run the command in the python environment we just created***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb187ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run this command if it takes too long just run it on the command prompt, inside the python environment\n",
    "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22eadcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0+cu102 (NVIDIA GeForce GTX 1660 Ti)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954d7ad",
   "metadata": {},
   "source": [
    "## Clone Repository\n",
    "Clone yolov5 repository by ***ultralytics*** from this link https://github.com/ultralytics/yolov5\n",
    "\n",
    "***Make sure that git has already installed in your computer and enabled to be executed from any file directory*** (set git into the environment variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61b16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib>=3.2.2\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 5)) (1.22.3)\n",
      "Collecting opencv-python>=4.1.1\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 7)) (9.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Collecting requests>=2.23.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Using cached scipy-1.8.0-cp38-cp38-win_amd64.whl (36.9 MB)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 11)) (1.9.0+cu102)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from -r requirements.txt (line 12)) (0.10.0+cu102)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Using cached pandas-1.4.2-cp38-cp38-win_amd64.whl (10.6 MB)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Collecting thop\n",
      "  Using cached thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-win_amd64.whl (55 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (21.3)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tqdm>=4.41.0->-r requirements.txt (line 13)) (0.4.4)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.20.1-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.46.1-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (62.3.0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.8.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, pyasn1, certifi, werkzeug, urllib3, tqdm, tensorboard-data-server, scipy, rsa, pyasn1-modules, protobuf, opencv-python, oauthlib, kiwisolver, importlib-metadata, idna, grpcio, fonttools, cycler, charset-normalizer, cachetools, absl-py, thop, requests, pandas, matplotlib, markdown, google-auth, seaborn, requests-oauthlib, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.0.0 cachetools-5.1.0 certifi-2021.10.8 charset-normalizer-2.0.12 cycler-0.11.0 fonttools-4.33.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.1 idna-3.3 importlib-metadata-4.11.3 kiwisolver-1.4.2 markdown-3.3.7 matplotlib-3.5.2 oauthlib-3.2.0 opencv-python-4.5.5.64 pandas-1.4.2 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytz-2022.1 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 scipy-1.8.0 seaborn-0.11.2 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 thop-0.0.31.post2005241907 tqdm-4.64.0 urllib3-1.26.9 werkzeug-2.1.2\n",
      "Collecting roboflow\n",
      "  Using cached roboflow-0.2.4-py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (4.5.5.64)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (6.0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n",
      "Collecting kiwisolver==1.3.1\n",
      "  Using cached kiwisolver-1.3.1-cp38-cp38-win_amd64.whl (51 kB)\n",
      "Collecting idna==2.10\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-toolbelt\n",
      "  Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (4.64.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (3.5.2)\n",
      "Collecting urllib3==1.26.6\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi==2021.5.30\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (9.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from roboflow) (2.27.1)\n",
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Collecting chardet==4.0.0\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting cycler==0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib->roboflow) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\.virtualenvs\\license-plate-object-detection-uhb0spub\\lib\\site-packages (from requests->roboflow) (2.0.12)\n",
      "Installing collected packages: wget, certifi, urllib3, python-dotenv, pyparsing, kiwisolver, idna, cycler, chardet, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.2\n",
      "    Uninstalling kiwisolver-1.4.2:\n",
      "      Successfully uninstalled kiwisolver-1.4.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 idna-2.10 kiwisolver-1.3.1 pyparsing-2.4.7 python-dotenv-0.20.0 requests-toolbelt-0.9.1 roboflow-0.2.4 urllib3-1.26.6 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "# clone the repo from this link 'https://github.com/ultralytics/yolov5.git'\n",
    "git_https = 'https://github.com/ultralytics/yolov5.git'\n",
    "folder_name = 'yolov5'\n",
    "if not os.path.exists(os.path.join(os.getcwd(), folder_name)):\n",
    "    !git clone {git_https}\n",
    "else:\n",
    "    !cd yolov5 && git pull\n",
    "    print(folder_name, 'already exists and up to date')\n",
    "\n",
    "# install requirements of yolov5\n",
    "!cd yolov5 && pip install -r requirements.txt\n",
    "# install roboflow for data pulling\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3448aab",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "After collecting our data, we will be using roboflow (can be accessed from this [link](https://roboflow.com/)) which is a tool for anotating region of interest. In this case, the region of interest is license plate. After anotating, we can export into any form of a dataset that will be accepted by our model. We can export it manually or using an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46e687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling costum-data created from roboflow website using API\n",
    "####################################TEMPLATE EXAMPLE#########################################\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"***************\")\n",
    "# project = rf.workspace(\"augmented-startups\").project(\"vehicle-registration-plates-trudk\")\n",
    "# dataset = project.version(2).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af661e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset doesn't exists\n",
      "location of dataset =  C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\datasets\\DATASET_NAME\n"
     ]
    }
   ],
   "source": [
    "# Setting up location for the dataset\n",
    "DATASET_PARENT_FOLDER = os.path.join(os.getcwd(), 'datasets')\n",
    "DATASET_FOLDER_NAME = 'DATASET_NAME' # filled later becase the dataset is still being collected\n",
    "DATASET_LOCATION = os.path.join(DATASET_PARENT_FOLDER, DATASET_FOLDER_NAME)\n",
    "\n",
    "if not os.path.exists(DATASET_LOCATION):\n",
    "    print(\"dataset doesn't exists\")\n",
    "else:\n",
    "    print(\"dataset already exists\")\n",
    "    \n",
    "\n",
    "print('location of dataset = ', DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3c8aa",
   "metadata": {},
   "source": [
    "Checking up the data.yaml inside the **DATASET_LOCATION** because the object detection API that is used needs it to find information where we put our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look inside the data.yaml file\n",
    "import yaml\n",
    "with open(os.path.join(DATASET_LOCATION, \"data.yaml\"), \"r\") as stream:\n",
    "    try:\n",
    "        content = yaml.safe_load(stream) \n",
    "        # print the content of data.yaml file\n",
    "        # we need to change the train and val path\n",
    "        for key, vals in content.items():\n",
    "            print(key, '=', vals)\n",
    "            \n",
    "        num_classes= content['nc']\n",
    "        print('num of classes = ', num_classes)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# number of classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00148dc5",
   "metadata": {},
   "source": [
    "## Configure Yolov5 Model\n",
    "We can do this configuring the .yaml file of that model that has been provided inside the yolov5 repo that we clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07c4bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## Yolo V5 default version ##############################\n",
      "yolov5l.yaml\n",
      "yolov5m.yaml\n",
      "yolov5n.yaml\n",
      "yolov5s.yaml\n",
      "yolov5x.yaml\n",
      "\n",
      "############################## Yolo V5 version 6 ##############################\n",
      "yolov5l6.yaml\n",
      "yolov5m6.yaml\n",
      "yolov5n6.yaml\n",
      "yolov5s6.yaml\n",
      "yolov5x6.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_directory = os.path.join(os.getcwd(), 'yolov5', 'models')\n",
    "print('\\n' + 30*'#'+ ' Yolo V5 default version ' + 30*'#')\n",
    "for file in os.listdir(model_directory):\n",
    "    if file.endswith('.yaml'):\n",
    "        print(file)\n",
    "\n",
    "print('\\n' + 30*'#'+ ' Yolo V5 version 6 ' + 30*'#')\n",
    "for file in os.listdir(model_directory+'/hub'):\n",
    "    if file in ['yolov5l6.yaml',  'yolov5m6.yaml', 'yolov5n6.yaml', 'yolov5s6.yaml', 'yolov5x6.yaml']:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ade33",
   "metadata": {},
   "source": [
    "For this project we will be using the Yolo V5 version 6 as our pretrained model for transfer learning the size of the model will be picked based capability of local machine. Don't use heavy model for training if teh hardware capabilty can't keep up with it. There must be a trade off between using **-small size and accuracy model-** or **-big size and high accuracy model-**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a7290c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov5l6.yaml\n",
      "{'nc': 80, 'depth_multiple': 1.0, 'width_multiple': 1.0, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5m6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.67, 'width_multiple': 0.75, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5n6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.33, 'width_multiple': 0.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5s6.yaml\n",
      "{'nc': 80, 'depth_multiple': 0.33, 'width_multiple': 0.5, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "yolov5x6.yaml\n",
      "{'nc': 80, 'depth_multiple': 1.33, 'width_multiple': 1.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "yolov5_v6_yamls = [\n",
    "    'yolov5l6.yaml',  \n",
    "    'yolov5m6.yaml', \n",
    "    'yolov5n6.yaml', \n",
    "    'yolov5s6.yaml', \n",
    "    'yolov5x6.yaml',\n",
    "]\n",
    "\n",
    "for file in os.listdir(os.path.join(model_directory, 'hub')):\n",
    "    if file in yolov5_v6_yamls:\n",
    "        with open(os.path.join(model_directory, 'hub', file), \"r\") as stream:\n",
    "            try:\n",
    "                content = yaml.safe_load(stream)\n",
    "                print(file)\n",
    "                print(content, '\\n')\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c1691",
   "metadata": {},
   "source": [
    "We can just change the ***nc*** into any number according to number of class that we want to predict. In this case, we use ***1*** because we only want to predict one class only which is license plate. Create a file call custom model .yaml by copying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e131fca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_yolov5l6.yaml already exists\n",
      "custom_yolov5m6.yaml already exists\n",
      "custom_yolov5n6.yaml already exists\n",
      "custom_yolov5s6.yaml already exists\n",
      "custom_yolov5x6.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "# create a new costume .yaml folder to enable the model to predict 1 class only\n",
    "# copy the contents of the .yaml file which is identified by the model's name\n",
    "model_folder = os.path.join(os.getcwd(), 'yolov5', 'models', 'hub')\n",
    "\n",
    "for file in os.listdir(model_directory+'/hub'):\n",
    "    if file in yolov5_v6_yamls:\n",
    "        yaml_ori_path = os.path.join(model_directory, 'hub', file)\n",
    "        custom_yaml_name = 'custom_'+file\n",
    "        custom_yaml_path = os.path.join(model_directory, custom_yaml_name)\n",
    "        \n",
    "        if not os.path.exists(custom_yaml_path):\n",
    "            shutil.copy(yaml_ori_path, custom_yaml_path)\n",
    "            print(yaml_ori_path, 'has been copied to ', custom_yaml_path)\n",
    "        else:\n",
    "            print(custom_yaml_name, 'already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7fd56",
   "metadata": {},
   "source": [
    "Edit the .yaml file manually by using a notepad or using other code editor. The result can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44d81aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_yolov5l6.yaml\n",
      "{'nc': 1, 'depth_multiple': 1.0, 'width_multiple': 1.0, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5m6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.67, 'width_multiple': 0.75, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5n6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.33, 'width_multiple': 0.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5s6.yaml\n",
      "{'nc': 1, 'depth_multiple': 0.33, 'width_multiple': 0.5, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n",
      "custom_yolov5x6.yaml\n",
      "{'nc': 1, 'depth_multiple': 1.33, 'width_multiple': 1.25, 'anchors': [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [768, 3, 2]], [-1, 3, 'C3', [768]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [768, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 8], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 20], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 16], 1, 'Concat', [1]], [-1, 3, 'C3', [768, False]], [-1, 1, 'Conv', [768, 3, 2]], [[-1, 12], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results after editing the .yaml files for model configuration\n",
    "custom_yolov5_v6_yamls = [\n",
    "    'custom_yolov5l6.yaml',  \n",
    "    'custom_yolov5m6.yaml', \n",
    "    'custom_yolov5n6.yaml', \n",
    "    'custom_yolov5s6.yaml', \n",
    "    'custom_yolov5x6.yaml',\n",
    "]\n",
    "\n",
    "for file in os.listdir(model_directory):\n",
    "    if file in custom_yolov5_v6_yamls:\n",
    "        with open(os.path.join(model_directory, file), \"r\") as stream:\n",
    "            try:\n",
    "                content = yaml.safe_load(stream)\n",
    "                print(file)\n",
    "                print(content, '\\n')\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba25b16",
   "metadata": {},
   "source": [
    "## Training yolov5 model\n",
    "Since we will be preparing a python script (from /yolov5/train.py) for training, there are some arguments that we need to consider which are:\n",
    "1. ***img:*** define input image size\n",
    "2. ***batch:*** determine batch size\n",
    "3. ***epochs:*** define the number of training epochs. (Note: often, 3000+ are common here!).\n",
    "4. ***data:*** set the path to our yaml file.\n",
    "5. ***cfg:*** specify our model configuration.\n",
    "6. ***weights:*** specify a custom path to weights (if the file doesn't exist the model pretrained weights will be downloaded automatically)\n",
    "7. ***cache:*** cache images for faster training. The default value for this argument is using 'RAM' we can change it to using 'disk' for more storage.\n",
    "8. ***project:*** folder for results\n",
    "9. ***name:*** result names inside the **project** folder\n",
    "10. ***freeze:*** for input how many layers that want to be freezed start from index zero to n-1 layer. For transfer learning we usually freeze the **backbone layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "661f8b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd yolov5 && python train.py --img 640 --batch 32 --epochs 5 --data C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\datasets\\DATASET_NAME\\data.yaml --cfg C:\\Users\\USER\\Documents\\GitHub\\VePay-Go-ML\\license-plate-object-detection\\yolov5\\models\\custom_yolov5x6.yaml --weights yolov5s6.pt --workers 3 --cache disk --project train_results --name train --freeze 12\n"
     ]
    }
   ],
   "source": [
    "img = 640\n",
    "batch = 32\n",
    "epochs = 5\n",
    "data = os.path.join(DATASET_LOCATION, 'data.yaml')\n",
    "cfg = custom_yaml_path\n",
    "weights = 'yolov5s6.pt'\n",
    "workers= 3\n",
    "cache = 'disk'\n",
    "project = 'train_results' \n",
    "name = 'train'\n",
    "freeze = 12\n",
    "\n",
    "command = \"cd yolov5 && python train.py --img {} --batch {} --epochs {} --data {} --cfg {} --weights {} --workers {} --cache {} --project {} --name {} --freeze {}\".\\\n",
    "          format(img, batch, epochs, data, cfg, weights, workers, cache, project, name, freeze)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447fe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa9441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bcf00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884f3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e6aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f530254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca145a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6975340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0352a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b773f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "license-plate-object-detection (pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

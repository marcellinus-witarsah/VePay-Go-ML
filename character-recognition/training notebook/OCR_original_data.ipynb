{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hLCzw_T1HiHgXW1jj2iSNxF33bu4mWFb?usp=sharing)"
      ],
      "metadata": {
        "id": "MWbta5PjSq15"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4dch4aLFes"
      },
      "source": [
        "# Processing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because github can't accomodate files above 100 mb,  so dataset file need to uploaded to cloud storage. In this case, we use Google Drive. To acsess the file we need to mount it to Google Colab."
      ],
      "metadata": {
        "id": "i6gXlmXQTvel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8W0BTrLgyw",
        "outputId": "e62a1f07-58df-43f1-a164-ef4d404fa016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEwuaIMCHNEY",
        "outputId": "683b61f4-6fe2-4ded-e915-fad99a27548b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Capstone Project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/Capstone Project/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the section below, there is a code to unzip the dataset file."
      ],
      "metadata": {
        "id": "ZRndCbN1WPKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mXowBp1MRbl"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "# Extract the archive\n",
        "local_zip = './dataset_binary_ori.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/CNN letter Dataset')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the dataset that has been imported, run this code below."
      ],
      "metadata": {
        "id": "xYp5zBrnWYgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7EtWK_SXGem",
        "outputId": "a3d45691-ffe0-490e-f007-ba701d558b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training 0 images: 287\n",
            "total training 1 images: 630\n",
            "total training O images: 118\n",
            "['B2130UFD_jpg.rf.de4fec7252c0ce9f6f6a9974ef3b3242.jpgtest6.jpg', 'PHOTO-2022-05-17-16-44-24_jpg.rf.6c680fd260272e15a9ffab401254bd02.jpgtest4.jpg', 'plat--19-_jpg.rf.7798c30ebc9f4d90c366fbd452b0523e.jpgtest6.jpg', 'plat-129-1_jpg.rf.2ed13e8cb3ab8f824edb987fcb13aa27.jpgtest4.jpg', 'B1059KCT-2-_jpg.rf.b5a93fffa6661f2572573d8232a811e3.jpgtest4 - Copy.jpg', 'BK1110W_jpg.rf.97ee2c7f68cdb1f328ef9124dcffee8b.jpgtest6.jpg', '20220517_123540_jpg.rf.81f13f5fd581bcf5784b152723eaef8b.jpgtest4.jpg', '2022-05-15-10_12_36-20220514_112722-mp4---VLC-media-player_jpg.rf.f84694e6efc999df4dabd3a243773491.jpgtest3.jpg', 'DA1401CE_jpg.rf.a0cba506815f42d2a15135592191a684.jpgtest7.jpg', 'plat-78-1_jpg.rf.a04494b648071e700a070b90d9775e79.jpgtest4.jpg']\n",
            "['IMG-20220515-WA0048_jpg.rf.349042fe794163ac7c0172aa8141b623.jpgtest8.jpg', 'plat--38-_jpg.rf.ec6c5cf8a1fb2d7ea29b258e76df55a0.jpgtest3.jpg', 'plat-58-1_jpg.rf.9c571aceee1348cd3002fa023b2fba6c.jpgtest1.jpg', 'B1925BOF-1-_jpg.rf.0df53e028f87ebf21bb22da9cdfcb472.jpgtest2.jpg', 'BG1651ZE_jpg.rf.4985b38bbd6cd056120b8d87e96a275e.jpgtest3.jpg', 'B1095CKV_jpg.rf.ac1478f7ebe45e6271c6988344dea7d4.jpgtest2.jpg', '20220516_145103_jpg.rf.598f12bed2bd6abca825fd65fad9e7c8.jpgtest3.jpg', 'B1134UVL_jpg.rf.a7cf9ff5590efff68298f0354dcf7156.jpgtest4.jpg', '20220517_132148_jpg.rf.431a35cd424bdba23078fb3d9854268c.jpgtest2.jpg', 'IMG_20220518_203105_jpg.rf.faaf26a767ccc61e1c749469555f4740.jpgtest2.jpg']\n",
            "['BL1126OZ_jpg.rf.b09b5620af5965bbafcfa836d9a678ae.jpgtest7.jpg', 'tes18.jpg', 'PHOTO-2022-05-17-17-35-52-2-_jpg.rf.c1570eb2a0e18c80408db12bcd878dcb.jpgtest8.jpg', 'Screenshot_20220517-135748_Gallery_jpg.rf.af1dec0020b7b062ddc3901d65aaa334.jpgtest7.jpg', 'tes13.jpg', 'img-p1652354746041-1_r73cty_jpg.rf.7974e3200d262b507a249f5d21cc4f21.jpgtest8.jpg', 'tes23.jpg', 'PHOTO-2022-05-17-17-34-03_jpg.rf.e79fb8842f8c81f7351d414b71ccfc35.jpgtest8.jpg', 'img-p1650265495119-2_fm8xfc_jpg.rf.62be07f7ad21c2b29c629cb6183df071.jpgtest8.jpg', 'B1827NOY_jpg.rf.5323f18e53642cc359ab06422c071a51.jpgtest7.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_dir = 'tmp/CNN letter Dataset/dataset_binary_ori/'\n",
        "\n",
        "class_0_dir = os.path.join(base_dir, '0')\n",
        "class_1_dir = os.path.join(base_dir, '1')\n",
        "class_O_dir = os.path.join(base_dir, 'O')\n",
        "\n",
        "print('total training 0 images:', len(os.listdir(class_0_dir)))\n",
        "print('total training 1 images:', len(os.listdir(class_1_dir)))\n",
        "print('total training O images:', len(os.listdir(class_O_dir)))\n",
        "\n",
        "class_0_files = os.listdir(class_0_dir)\n",
        "print(class_0_files[:10])\n",
        "\n",
        "class_1_files = os.listdir(class_1_dir)\n",
        "print(class_1_files[:10])\n",
        "\n",
        "class_O_files = os.listdir(class_O_dir)\n",
        "print(class_O_files[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VKv804GZC0n"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section below, we create layer for the model."
      ],
      "metadata": {
        "id": "9FJ-hVU2WoiS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLGEVLHKZFb6",
        "outputId": "f4d7fd61-be5b-4995-9dd5-eb213fe30ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 36)                2340      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361,380\n",
            "Trainable params: 361,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 64x64 with 1 bytes color\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', ),# kernel_regularizer='l1'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(36, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9PwAe06ZqYk"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCuWmzwRbicY"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will going to use `ImageDataGenerator` to preprocess dataset images. These images has been grouped into the folder based on their true value. In order to make the model could recognize the folder as a label, we use `flow_from_directory` method."
      ],
      "metadata": {
        "id": "szVnTzaoW3Cn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWMQI22xblM6",
        "outputId": "b1825f24-236f-464e-f27a-75e76eff8d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4101 images belonging to 36 classes.\n",
            "Found 1730 images belonging to 36 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"tmp/CNN letter Dataset/dataset_binary_ori/\"\n",
        "training_datagen = ImageDataGenerator(# rescale=1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.1,\n",
        "      fill_mode='nearest',\n",
        "      validation_split=0.3) # augmentation is optional, if the dataset has much variance of data, augmentation is not necessary.\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(64,64), # make sure target size match with model input\n",
        "\tclass_mode='sparse', # make sure class_mode match with loss in compile code\n",
        "  batch_size=64,\n",
        "  color_mode='grayscale',# make sure color_mode match with model input. Grayscale means the images has 1 bit depth of color. \n",
        "  seed=123,\n",
        "  subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(64,64), # make sure target size match with model input\n",
        "\tclass_mode='sparse',\n",
        "  batch_size=64,\n",
        "  color_mode='grayscale',\n",
        "  seed=123,\n",
        "  subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nASO7UYcHUQ"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will going to start train the model."
      ],
      "metadata": {
        "id": "P2MSThXDZKgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class `myCallback` are used to stop the model training if the parameter has been fulfilled. In this case, we use `val_accuracy` as the parameter."
      ],
      "metadata": {
        "id": "iM2d-8z5ZPMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO42wHPnQoO5"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 95 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('val_accuracy') > 0.95):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nAccuracy higher than 95% so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to train the model."
      ],
      "metadata": {
        "id": "x6Nzta02Zr8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kn2JGBgcBx-",
        "outputId": "449665f9-7bdd-44f0-86a5-b7cae5ead3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3374 - accuracy: 0.8886 - val_loss: 0.1764 - val_accuracy: 0.9428\n",
            "Epoch 2/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3385 - accuracy: 0.8898 - val_loss: 0.1851 - val_accuracy: 0.9382\n",
            "Epoch 3/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3479 - accuracy: 0.8900 - val_loss: 0.1748 - val_accuracy: 0.9445\n",
            "Epoch 4/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3361 - accuracy: 0.8927 - val_loss: 0.1941 - val_accuracy: 0.9358\n",
            "Epoch 5/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3124 - accuracy: 0.9039 - val_loss: 0.1798 - val_accuracy: 0.9416\n",
            "Epoch 6/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3704 - accuracy: 0.8842 - val_loss: 0.1926 - val_accuracy: 0.9358\n",
            "Epoch 7/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3433 - accuracy: 0.8873 - val_loss: 0.1851 - val_accuracy: 0.9457\n",
            "Epoch 8/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3237 - accuracy: 0.8947 - val_loss: 0.1958 - val_accuracy: 0.9405\n",
            "Epoch 9/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3562 - accuracy: 0.8873 - val_loss: 0.2003 - val_accuracy: 0.9382\n",
            "Epoch 10/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3429 - accuracy: 0.8895 - val_loss: 0.1948 - val_accuracy: 0.9410\n",
            "Epoch 11/500\n",
            "65/65 [==============================] - 5s 80ms/step - loss: 0.3300 - accuracy: 0.8939 - val_loss: 0.1759 - val_accuracy: 0.9445\n",
            "Epoch 12/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3146 - accuracy: 0.9015 - val_loss: 0.1986 - val_accuracy: 0.9393\n",
            "Epoch 13/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3313 - accuracy: 0.8961 - val_loss: 0.1909 - val_accuracy: 0.9387\n",
            "Epoch 14/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3207 - accuracy: 0.8998 - val_loss: 0.1723 - val_accuracy: 0.9462\n",
            "Epoch 15/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3144 - accuracy: 0.8998 - val_loss: 0.1649 - val_accuracy: 0.9480\n",
            "Epoch 16/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3193 - accuracy: 0.9037 - val_loss: 0.1758 - val_accuracy: 0.9491\n",
            "Epoch 17/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3273 - accuracy: 0.8978 - val_loss: 0.1797 - val_accuracy: 0.9451\n",
            "Epoch 18/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3088 - accuracy: 0.9042 - val_loss: 0.1812 - val_accuracy: 0.9410\n",
            "Epoch 19/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3089 - accuracy: 0.9017 - val_loss: 0.1850 - val_accuracy: 0.9480\n",
            "Epoch 20/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3252 - accuracy: 0.8976 - val_loss: 0.1810 - val_accuracy: 0.9405\n",
            "Epoch 21/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3297 - accuracy: 0.8966 - val_loss: 0.1657 - val_accuracy: 0.9509\n",
            "Epoch 22/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3189 - accuracy: 0.9069 - val_loss: 0.1778 - val_accuracy: 0.9410\n",
            "Epoch 23/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3344 - accuracy: 0.8917 - val_loss: 0.1583 - val_accuracy: 0.9514\n",
            "Epoch 24/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3298 - accuracy: 0.8944 - val_loss: 0.1832 - val_accuracy: 0.9486\n",
            "Epoch 25/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3214 - accuracy: 0.8959 - val_loss: 0.1805 - val_accuracy: 0.9457\n",
            "Epoch 26/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3265 - accuracy: 0.8966 - val_loss: 0.1713 - val_accuracy: 0.9462\n",
            "Epoch 27/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3194 - accuracy: 0.9000 - val_loss: 0.1753 - val_accuracy: 0.9434\n",
            "Epoch 28/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3190 - accuracy: 0.8959 - val_loss: 0.1834 - val_accuracy: 0.9451\n",
            "Epoch 29/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3492 - accuracy: 0.8886 - val_loss: 0.1907 - val_accuracy: 0.9451\n",
            "Epoch 30/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3054 - accuracy: 0.9032 - val_loss: 0.2007 - val_accuracy: 0.9451\n",
            "Epoch 31/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3305 - accuracy: 0.8944 - val_loss: 0.1521 - val_accuracy: 0.9491\n",
            "Epoch 32/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3237 - accuracy: 0.8966 - val_loss: 0.1849 - val_accuracy: 0.9405\n",
            "Epoch 33/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3350 - accuracy: 0.8942 - val_loss: 0.1562 - val_accuracy: 0.9486\n",
            "Epoch 34/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3067 - accuracy: 0.8988 - val_loss: 0.1884 - val_accuracy: 0.9428\n",
            "Epoch 35/500\n",
            "65/65 [==============================] - 4s 64ms/step - loss: 0.3259 - accuracy: 0.8961 - val_loss: 0.1755 - val_accuracy: 0.9445\n",
            "Epoch 36/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3017 - accuracy: 0.8981 - val_loss: 0.1706 - val_accuracy: 0.9497\n",
            "Epoch 37/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3278 - accuracy: 0.8983 - val_loss: 0.1668 - val_accuracy: 0.9439\n",
            "Epoch 38/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3174 - accuracy: 0.9005 - val_loss: 0.1589 - val_accuracy: 0.9462\n",
            "Epoch 39/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3214 - accuracy: 0.8964 - val_loss: 0.1512 - val_accuracy: 0.9486\n",
            "Epoch 40/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3079 - accuracy: 0.9027 - val_loss: 0.1546 - val_accuracy: 0.9480\n",
            "Epoch 41/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3078 - accuracy: 0.9049 - val_loss: 0.1676 - val_accuracy: 0.9514\n",
            "Epoch 42/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2926 - accuracy: 0.9090 - val_loss: 0.1748 - val_accuracy: 0.9445\n",
            "Epoch 43/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3061 - accuracy: 0.9061 - val_loss: 0.1840 - val_accuracy: 0.9370\n",
            "Epoch 44/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3143 - accuracy: 0.8978 - val_loss: 0.2006 - val_accuracy: 0.9382\n",
            "Epoch 45/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3088 - accuracy: 0.9022 - val_loss: 0.1736 - val_accuracy: 0.9422\n",
            "Epoch 46/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3133 - accuracy: 0.8969 - val_loss: 0.1546 - val_accuracy: 0.9526\n",
            "Epoch 47/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2775 - accuracy: 0.9098 - val_loss: 0.1683 - val_accuracy: 0.9503\n",
            "Epoch 48/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3266 - accuracy: 0.8990 - val_loss: 0.1634 - val_accuracy: 0.9457\n",
            "Epoch 49/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3410 - accuracy: 0.8971 - val_loss: 0.1799 - val_accuracy: 0.9428\n",
            "Epoch 50/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2991 - accuracy: 0.9039 - val_loss: 0.1794 - val_accuracy: 0.9468\n",
            "Epoch 51/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3076 - accuracy: 0.8959 - val_loss: 0.1591 - val_accuracy: 0.9503\n",
            "Epoch 52/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3066 - accuracy: 0.9090 - val_loss: 0.1849 - val_accuracy: 0.9457\n",
            "Epoch 53/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3075 - accuracy: 0.8995 - val_loss: 0.1742 - val_accuracy: 0.9457\n",
            "Epoch 54/500\n",
            "65/65 [==============================] - 6s 86ms/step - loss: 0.3028 - accuracy: 0.9037 - val_loss: 0.1539 - val_accuracy: 0.9497\n",
            "Epoch 55/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2907 - accuracy: 0.9005 - val_loss: 0.1592 - val_accuracy: 0.9532\n",
            "Epoch 56/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2940 - accuracy: 0.9022 - val_loss: 0.1607 - val_accuracy: 0.9480\n",
            "Epoch 57/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2742 - accuracy: 0.9120 - val_loss: 0.1825 - val_accuracy: 0.9480\n",
            "Epoch 58/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2999 - accuracy: 0.9081 - val_loss: 0.1632 - val_accuracy: 0.9486\n",
            "Epoch 59/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.3218 - accuracy: 0.8903 - val_loss: 0.1597 - val_accuracy: 0.9532\n",
            "Epoch 60/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3063 - accuracy: 0.9071 - val_loss: 0.1682 - val_accuracy: 0.9486\n",
            "Epoch 61/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2810 - accuracy: 0.9086 - val_loss: 0.1497 - val_accuracy: 0.9497\n",
            "Epoch 62/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3092 - accuracy: 0.8986 - val_loss: 0.1733 - val_accuracy: 0.9393\n",
            "Epoch 63/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3163 - accuracy: 0.8993 - val_loss: 0.1671 - val_accuracy: 0.9491\n",
            "Epoch 64/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3076 - accuracy: 0.9049 - val_loss: 0.2058 - val_accuracy: 0.9382\n",
            "Epoch 65/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3007 - accuracy: 0.9022 - val_loss: 0.1614 - val_accuracy: 0.9514\n",
            "Epoch 66/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2726 - accuracy: 0.9105 - val_loss: 0.1571 - val_accuracy: 0.9491\n",
            "Epoch 67/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3165 - accuracy: 0.8981 - val_loss: 0.1971 - val_accuracy: 0.9393\n",
            "Epoch 68/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2925 - accuracy: 0.9030 - val_loss: 0.1720 - val_accuracy: 0.9434\n",
            "Epoch 69/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3129 - accuracy: 0.9069 - val_loss: 0.1671 - val_accuracy: 0.9457\n",
            "Epoch 70/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3011 - accuracy: 0.9051 - val_loss: 0.1666 - val_accuracy: 0.9474\n",
            "Epoch 71/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2853 - accuracy: 0.9095 - val_loss: 0.1633 - val_accuracy: 0.9457\n",
            "Epoch 72/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3012 - accuracy: 0.9059 - val_loss: 0.1558 - val_accuracy: 0.9457\n",
            "Epoch 73/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2982 - accuracy: 0.9047 - val_loss: 0.1645 - val_accuracy: 0.9532\n",
            "Epoch 74/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2847 - accuracy: 0.9176 - val_loss: 0.1514 - val_accuracy: 0.9503\n",
            "Epoch 75/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2944 - accuracy: 0.9093 - val_loss: 0.1774 - val_accuracy: 0.9434\n",
            "Epoch 76/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2831 - accuracy: 0.9144 - val_loss: 0.1631 - val_accuracy: 0.9497\n",
            "Epoch 77/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2956 - accuracy: 0.9000 - val_loss: 0.1736 - val_accuracy: 0.9422\n",
            "Epoch 78/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2774 - accuracy: 0.9115 - val_loss: 0.1512 - val_accuracy: 0.9538\n",
            "Epoch 79/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2802 - accuracy: 0.9071 - val_loss: 0.1809 - val_accuracy: 0.9434\n",
            "Epoch 80/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2784 - accuracy: 0.9073 - val_loss: 0.1846 - val_accuracy: 0.9486\n",
            "Epoch 81/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2941 - accuracy: 0.9081 - val_loss: 0.1682 - val_accuracy: 0.9410\n",
            "Epoch 82/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2971 - accuracy: 0.9073 - val_loss: 0.1606 - val_accuracy: 0.9497\n",
            "Epoch 83/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3019 - accuracy: 0.9003 - val_loss: 0.1543 - val_accuracy: 0.9538\n",
            "Epoch 84/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2657 - accuracy: 0.9178 - val_loss: 0.1655 - val_accuracy: 0.9474\n",
            "Epoch 85/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.3016 - accuracy: 0.9020 - val_loss: 0.1811 - val_accuracy: 0.9468\n",
            "Epoch 86/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2910 - accuracy: 0.9054 - val_loss: 0.1643 - val_accuracy: 0.9474\n",
            "Epoch 87/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2692 - accuracy: 0.9115 - val_loss: 0.1407 - val_accuracy: 0.9538\n",
            "Epoch 88/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2993 - accuracy: 0.9030 - val_loss: 0.1834 - val_accuracy: 0.9428\n",
            "Epoch 89/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.3014 - accuracy: 0.9042 - val_loss: 0.1623 - val_accuracy: 0.9480\n",
            "Epoch 90/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2696 - accuracy: 0.9137 - val_loss: 0.1703 - val_accuracy: 0.9497\n",
            "Epoch 91/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2968 - accuracy: 0.9000 - val_loss: 0.1519 - val_accuracy: 0.9532\n",
            "Epoch 92/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2882 - accuracy: 0.9073 - val_loss: 0.1658 - val_accuracy: 0.9451\n",
            "Epoch 93/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2913 - accuracy: 0.9076 - val_loss: 0.1780 - val_accuracy: 0.9410\n",
            "Epoch 94/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2735 - accuracy: 0.9105 - val_loss: 0.1551 - val_accuracy: 0.9428\n",
            "Epoch 95/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2913 - accuracy: 0.9076 - val_loss: 0.1480 - val_accuracy: 0.9566\n",
            "Epoch 96/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2886 - accuracy: 0.9078 - val_loss: 0.1338 - val_accuracy: 0.9618\n",
            "Epoch 97/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2838 - accuracy: 0.9088 - val_loss: 0.1638 - val_accuracy: 0.9491\n",
            "Epoch 98/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2867 - accuracy: 0.9095 - val_loss: 0.1794 - val_accuracy: 0.9445\n",
            "Epoch 99/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2901 - accuracy: 0.9095 - val_loss: 0.1455 - val_accuracy: 0.9561\n",
            "Epoch 100/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2923 - accuracy: 0.9095 - val_loss: 0.1501 - val_accuracy: 0.9555\n",
            "Epoch 101/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2869 - accuracy: 0.9120 - val_loss: 0.1581 - val_accuracy: 0.9566\n",
            "Epoch 102/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2882 - accuracy: 0.9047 - val_loss: 0.1583 - val_accuracy: 0.9520\n",
            "Epoch 103/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2681 - accuracy: 0.9127 - val_loss: 0.1600 - val_accuracy: 0.9474\n",
            "Epoch 104/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2879 - accuracy: 0.9027 - val_loss: 0.1965 - val_accuracy: 0.9405\n",
            "Epoch 105/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2772 - accuracy: 0.9134 - val_loss: 0.1596 - val_accuracy: 0.9503\n",
            "Epoch 106/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3050 - accuracy: 0.9049 - val_loss: 0.1747 - val_accuracy: 0.9428\n",
            "Epoch 107/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2868 - accuracy: 0.9071 - val_loss: 0.1697 - val_accuracy: 0.9468\n",
            "Epoch 108/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2962 - accuracy: 0.9030 - val_loss: 0.1903 - val_accuracy: 0.9509\n",
            "Epoch 109/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2853 - accuracy: 0.9073 - val_loss: 0.1817 - val_accuracy: 0.9462\n",
            "Epoch 110/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2799 - accuracy: 0.9108 - val_loss: 0.1564 - val_accuracy: 0.9509\n",
            "Epoch 111/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2830 - accuracy: 0.9086 - val_loss: 0.1631 - val_accuracy: 0.9457\n",
            "Epoch 112/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3008 - accuracy: 0.9037 - val_loss: 0.1508 - val_accuracy: 0.9503\n",
            "Epoch 113/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2891 - accuracy: 0.9042 - val_loss: 0.1591 - val_accuracy: 0.9520\n",
            "Epoch 114/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2903 - accuracy: 0.9098 - val_loss: 0.1461 - val_accuracy: 0.9509\n",
            "Epoch 115/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2980 - accuracy: 0.9022 - val_loss: 0.1565 - val_accuracy: 0.9543\n",
            "Epoch 116/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2871 - accuracy: 0.9054 - val_loss: 0.1837 - val_accuracy: 0.9451\n",
            "Epoch 117/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2870 - accuracy: 0.9127 - val_loss: 0.1606 - val_accuracy: 0.9497\n",
            "Epoch 118/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2726 - accuracy: 0.9156 - val_loss: 0.1639 - val_accuracy: 0.9457\n",
            "Epoch 119/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2807 - accuracy: 0.9139 - val_loss: 0.1763 - val_accuracy: 0.9457\n",
            "Epoch 120/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2916 - accuracy: 0.9081 - val_loss: 0.1890 - val_accuracy: 0.9462\n",
            "Epoch 121/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2648 - accuracy: 0.9168 - val_loss: 0.1290 - val_accuracy: 0.9532\n",
            "Epoch 122/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2760 - accuracy: 0.9073 - val_loss: 0.1606 - val_accuracy: 0.9480\n",
            "Epoch 123/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2735 - accuracy: 0.9095 - val_loss: 0.1644 - val_accuracy: 0.9457\n",
            "Epoch 124/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2727 - accuracy: 0.9115 - val_loss: 0.1697 - val_accuracy: 0.9514\n",
            "Epoch 125/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2608 - accuracy: 0.9125 - val_loss: 0.1425 - val_accuracy: 0.9572\n",
            "Epoch 126/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2815 - accuracy: 0.9044 - val_loss: 0.1572 - val_accuracy: 0.9497\n",
            "Epoch 127/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3108 - accuracy: 0.9027 - val_loss: 0.1781 - val_accuracy: 0.9439\n",
            "Epoch 128/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2749 - accuracy: 0.9122 - val_loss: 0.1546 - val_accuracy: 0.9480\n",
            "Epoch 129/500\n",
            "65/65 [==============================] - 6s 85ms/step - loss: 0.2874 - accuracy: 0.9132 - val_loss: 0.1520 - val_accuracy: 0.9514\n",
            "Epoch 130/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2897 - accuracy: 0.9088 - val_loss: 0.1650 - val_accuracy: 0.9520\n",
            "Epoch 131/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2868 - accuracy: 0.9100 - val_loss: 0.1435 - val_accuracy: 0.9543\n",
            "Epoch 132/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2753 - accuracy: 0.9100 - val_loss: 0.1643 - val_accuracy: 0.9514\n",
            "Epoch 133/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2848 - accuracy: 0.9078 - val_loss: 0.1736 - val_accuracy: 0.9497\n",
            "Epoch 134/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2688 - accuracy: 0.9120 - val_loss: 0.1541 - val_accuracy: 0.9538\n",
            "Epoch 135/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2778 - accuracy: 0.9071 - val_loss: 0.1595 - val_accuracy: 0.9457\n",
            "Epoch 136/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2661 - accuracy: 0.9156 - val_loss: 0.1505 - val_accuracy: 0.9526\n",
            "Epoch 137/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2763 - accuracy: 0.9112 - val_loss: 0.1608 - val_accuracy: 0.9538\n",
            "Epoch 138/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2870 - accuracy: 0.9098 - val_loss: 0.1575 - val_accuracy: 0.9480\n",
            "Epoch 139/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2702 - accuracy: 0.9156 - val_loss: 0.1726 - val_accuracy: 0.9468\n",
            "Epoch 140/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2893 - accuracy: 0.9110 - val_loss: 0.1672 - val_accuracy: 0.9457\n",
            "Epoch 141/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2842 - accuracy: 0.9073 - val_loss: 0.1590 - val_accuracy: 0.9474\n",
            "Epoch 142/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2625 - accuracy: 0.9161 - val_loss: 0.1458 - val_accuracy: 0.9572\n",
            "Epoch 143/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2689 - accuracy: 0.9103 - val_loss: 0.1421 - val_accuracy: 0.9486\n",
            "Epoch 144/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2831 - accuracy: 0.9127 - val_loss: 0.1542 - val_accuracy: 0.9491\n",
            "Epoch 145/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2700 - accuracy: 0.9137 - val_loss: 0.1585 - val_accuracy: 0.9503\n",
            "Epoch 146/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2663 - accuracy: 0.9120 - val_loss: 0.1399 - val_accuracy: 0.9595\n",
            "Epoch 147/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2768 - accuracy: 0.9137 - val_loss: 0.1663 - val_accuracy: 0.9462\n",
            "Epoch 148/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2990 - accuracy: 0.9044 - val_loss: 0.1392 - val_accuracy: 0.9572\n",
            "Epoch 149/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2519 - accuracy: 0.9164 - val_loss: 0.1677 - val_accuracy: 0.9520\n",
            "Epoch 150/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.3077 - accuracy: 0.9030 - val_loss: 0.1703 - val_accuracy: 0.9491\n",
            "Epoch 151/500\n",
            "65/65 [==============================] - 4s 65ms/step - loss: 0.2684 - accuracy: 0.9105 - val_loss: 0.1634 - val_accuracy: 0.9462\n",
            "Epoch 152/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2694 - accuracy: 0.9112 - val_loss: 0.1510 - val_accuracy: 0.9503\n",
            "Epoch 153/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2717 - accuracy: 0.9098 - val_loss: 0.1566 - val_accuracy: 0.9480\n",
            "Epoch 154/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2615 - accuracy: 0.9173 - val_loss: 0.1513 - val_accuracy: 0.9497\n",
            "Epoch 155/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2655 - accuracy: 0.9117 - val_loss: 0.1580 - val_accuracy: 0.9457\n",
            "Epoch 156/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2530 - accuracy: 0.9168 - val_loss: 0.1534 - val_accuracy: 0.9549\n",
            "Epoch 157/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2580 - accuracy: 0.9149 - val_loss: 0.1787 - val_accuracy: 0.9422\n",
            "Epoch 158/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2707 - accuracy: 0.9117 - val_loss: 0.1749 - val_accuracy: 0.9422\n",
            "Epoch 159/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2730 - accuracy: 0.9105 - val_loss: 0.1594 - val_accuracy: 0.9509\n",
            "Epoch 160/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2806 - accuracy: 0.9073 - val_loss: 0.1526 - val_accuracy: 0.9509\n",
            "Epoch 161/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2706 - accuracy: 0.9186 - val_loss: 0.1293 - val_accuracy: 0.9624\n",
            "Epoch 162/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2700 - accuracy: 0.9181 - val_loss: 0.1527 - val_accuracy: 0.9538\n",
            "Epoch 163/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2621 - accuracy: 0.9144 - val_loss: 0.1640 - val_accuracy: 0.9532\n",
            "Epoch 164/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2670 - accuracy: 0.9151 - val_loss: 0.1490 - val_accuracy: 0.9584\n",
            "Epoch 165/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3031 - accuracy: 0.9083 - val_loss: 0.1845 - val_accuracy: 0.9439\n",
            "Epoch 166/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2801 - accuracy: 0.9134 - val_loss: 0.1601 - val_accuracy: 0.9486\n",
            "Epoch 167/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2593 - accuracy: 0.9171 - val_loss: 0.1563 - val_accuracy: 0.9497\n",
            "Epoch 168/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2475 - accuracy: 0.9212 - val_loss: 0.1454 - val_accuracy: 0.9538\n",
            "Epoch 169/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2752 - accuracy: 0.9125 - val_loss: 0.1636 - val_accuracy: 0.9509\n",
            "Epoch 170/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2824 - accuracy: 0.9103 - val_loss: 0.1864 - val_accuracy: 0.9422\n",
            "Epoch 171/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2759 - accuracy: 0.9168 - val_loss: 0.1562 - val_accuracy: 0.9532\n",
            "Epoch 172/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2715 - accuracy: 0.9093 - val_loss: 0.1463 - val_accuracy: 0.9509\n",
            "Epoch 173/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2725 - accuracy: 0.9151 - val_loss: 0.1528 - val_accuracy: 0.9520\n",
            "Epoch 174/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2670 - accuracy: 0.9110 - val_loss: 0.1486 - val_accuracy: 0.9532\n",
            "Epoch 175/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2733 - accuracy: 0.9139 - val_loss: 0.1623 - val_accuracy: 0.9526\n",
            "Epoch 176/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2619 - accuracy: 0.9134 - val_loss: 0.1449 - val_accuracy: 0.9578\n",
            "Epoch 177/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2647 - accuracy: 0.9193 - val_loss: 0.1365 - val_accuracy: 0.9566\n",
            "Epoch 178/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2681 - accuracy: 0.9100 - val_loss: 0.1481 - val_accuracy: 0.9572\n",
            "Epoch 179/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2646 - accuracy: 0.9147 - val_loss: 0.1930 - val_accuracy: 0.9428\n",
            "Epoch 180/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2537 - accuracy: 0.9210 - val_loss: 0.1497 - val_accuracy: 0.9555\n",
            "Epoch 181/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2496 - accuracy: 0.9181 - val_loss: 0.1383 - val_accuracy: 0.9584\n",
            "Epoch 182/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2599 - accuracy: 0.9168 - val_loss: 0.1682 - val_accuracy: 0.9497\n",
            "Epoch 183/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2798 - accuracy: 0.9108 - val_loss: 0.1683 - val_accuracy: 0.9491\n",
            "Epoch 184/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2630 - accuracy: 0.9149 - val_loss: 0.1439 - val_accuracy: 0.9491\n",
            "Epoch 185/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2558 - accuracy: 0.9171 - val_loss: 0.1564 - val_accuracy: 0.9509\n",
            "Epoch 186/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2689 - accuracy: 0.9115 - val_loss: 0.1558 - val_accuracy: 0.9503\n",
            "Epoch 187/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2535 - accuracy: 0.9168 - val_loss: 0.1374 - val_accuracy: 0.9549\n",
            "Epoch 188/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2704 - accuracy: 0.9178 - val_loss: 0.1503 - val_accuracy: 0.9566\n",
            "Epoch 189/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2608 - accuracy: 0.9181 - val_loss: 0.1508 - val_accuracy: 0.9509\n",
            "Epoch 190/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2545 - accuracy: 0.9176 - val_loss: 0.1410 - val_accuracy: 0.9590\n",
            "Epoch 191/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2507 - accuracy: 0.9183 - val_loss: 0.1545 - val_accuracy: 0.9503\n",
            "Epoch 192/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2598 - accuracy: 0.9205 - val_loss: 0.1664 - val_accuracy: 0.9503\n",
            "Epoch 193/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2576 - accuracy: 0.9181 - val_loss: 0.1424 - val_accuracy: 0.9549\n",
            "Epoch 194/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2618 - accuracy: 0.9142 - val_loss: 0.1328 - val_accuracy: 0.9584\n",
            "Epoch 195/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2648 - accuracy: 0.9159 - val_loss: 0.1603 - val_accuracy: 0.9538\n",
            "Epoch 196/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2703 - accuracy: 0.9176 - val_loss: 0.1374 - val_accuracy: 0.9618\n",
            "Epoch 197/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2560 - accuracy: 0.9159 - val_loss: 0.1403 - val_accuracy: 0.9555\n",
            "Epoch 198/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2480 - accuracy: 0.9271 - val_loss: 0.1429 - val_accuracy: 0.9538\n",
            "Epoch 199/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2735 - accuracy: 0.9134 - val_loss: 0.1591 - val_accuracy: 0.9526\n",
            "Epoch 200/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2623 - accuracy: 0.9176 - val_loss: 0.1563 - val_accuracy: 0.9468\n",
            "Epoch 201/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2571 - accuracy: 0.9147 - val_loss: 0.1554 - val_accuracy: 0.9509\n",
            "Epoch 202/500\n",
            "65/65 [==============================] - 6s 87ms/step - loss: 0.2458 - accuracy: 0.9266 - val_loss: 0.1609 - val_accuracy: 0.9532\n",
            "Epoch 203/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2462 - accuracy: 0.9217 - val_loss: 0.1358 - val_accuracy: 0.9590\n",
            "Epoch 204/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2619 - accuracy: 0.9183 - val_loss: 0.1645 - val_accuracy: 0.9491\n",
            "Epoch 205/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2570 - accuracy: 0.9139 - val_loss: 0.1440 - val_accuracy: 0.9526\n",
            "Epoch 206/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2679 - accuracy: 0.9122 - val_loss: 0.1493 - val_accuracy: 0.9520\n",
            "Epoch 207/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2333 - accuracy: 0.9198 - val_loss: 0.1720 - val_accuracy: 0.9445\n",
            "Epoch 208/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2407 - accuracy: 0.9222 - val_loss: 0.1590 - val_accuracy: 0.9468\n",
            "Epoch 209/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2659 - accuracy: 0.9137 - val_loss: 0.1565 - val_accuracy: 0.9520\n",
            "Epoch 210/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2575 - accuracy: 0.9134 - val_loss: 0.1436 - val_accuracy: 0.9532\n",
            "Epoch 211/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.3042 - accuracy: 0.9069 - val_loss: 0.1573 - val_accuracy: 0.9509\n",
            "Epoch 212/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2808 - accuracy: 0.9120 - val_loss: 0.2026 - val_accuracy: 0.9353\n",
            "Epoch 213/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2978 - accuracy: 0.9066 - val_loss: 0.1606 - val_accuracy: 0.9520\n",
            "Epoch 214/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2709 - accuracy: 0.9142 - val_loss: 0.1544 - val_accuracy: 0.9526\n",
            "Epoch 215/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2721 - accuracy: 0.9117 - val_loss: 0.1394 - val_accuracy: 0.9543\n",
            "Epoch 216/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2609 - accuracy: 0.9134 - val_loss: 0.1534 - val_accuracy: 0.9480\n",
            "Epoch 217/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2587 - accuracy: 0.9183 - val_loss: 0.1532 - val_accuracy: 0.9538\n",
            "Epoch 218/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2430 - accuracy: 0.9200 - val_loss: 0.1588 - val_accuracy: 0.9520\n",
            "Epoch 219/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2640 - accuracy: 0.9149 - val_loss: 0.1389 - val_accuracy: 0.9538\n",
            "Epoch 220/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2611 - accuracy: 0.9171 - val_loss: 0.1650 - val_accuracy: 0.9532\n",
            "Epoch 221/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2519 - accuracy: 0.9251 - val_loss: 0.1390 - val_accuracy: 0.9549\n",
            "Epoch 222/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2904 - accuracy: 0.9103 - val_loss: 0.1737 - val_accuracy: 0.9474\n",
            "Epoch 223/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2701 - accuracy: 0.9173 - val_loss: 0.1563 - val_accuracy: 0.9503\n",
            "Epoch 224/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2601 - accuracy: 0.9200 - val_loss: 0.1521 - val_accuracy: 0.9555\n",
            "Epoch 225/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2453 - accuracy: 0.9203 - val_loss: 0.1509 - val_accuracy: 0.9503\n",
            "Epoch 226/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2586 - accuracy: 0.9127 - val_loss: 0.1505 - val_accuracy: 0.9503\n",
            "Epoch 227/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2501 - accuracy: 0.9208 - val_loss: 0.1754 - val_accuracy: 0.9462\n",
            "Epoch 228/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2557 - accuracy: 0.9166 - val_loss: 0.1247 - val_accuracy: 0.9561\n",
            "Epoch 229/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2448 - accuracy: 0.9239 - val_loss: 0.1576 - val_accuracy: 0.9468\n",
            "Epoch 230/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2498 - accuracy: 0.9220 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
            "Epoch 231/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2724 - accuracy: 0.9134 - val_loss: 0.1289 - val_accuracy: 0.9671\n",
            "Epoch 232/500\n",
            "65/65 [==============================] - 4s 66ms/step - loss: 0.2379 - accuracy: 0.9234 - val_loss: 0.1374 - val_accuracy: 0.9538\n",
            "Epoch 233/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2642 - accuracy: 0.9164 - val_loss: 0.1822 - val_accuracy: 0.9457\n",
            "Epoch 234/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2707 - accuracy: 0.9147 - val_loss: 0.1396 - val_accuracy: 0.9555\n",
            "Epoch 235/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2564 - accuracy: 0.9176 - val_loss: 0.1707 - val_accuracy: 0.9468\n",
            "Epoch 236/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2628 - accuracy: 0.9188 - val_loss: 0.1426 - val_accuracy: 0.9474\n",
            "Epoch 237/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2387 - accuracy: 0.9205 - val_loss: 0.1474 - val_accuracy: 0.9578\n",
            "Epoch 238/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2398 - accuracy: 0.9256 - val_loss: 0.1518 - val_accuracy: 0.9509\n",
            "Epoch 239/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2526 - accuracy: 0.9168 - val_loss: 0.1460 - val_accuracy: 0.9532\n",
            "Epoch 240/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2402 - accuracy: 0.9222 - val_loss: 0.1716 - val_accuracy: 0.9480\n",
            "Epoch 241/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2586 - accuracy: 0.9164 - val_loss: 0.1224 - val_accuracy: 0.9578\n",
            "Epoch 242/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2535 - accuracy: 0.9176 - val_loss: 0.1501 - val_accuracy: 0.9538\n",
            "Epoch 243/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2670 - accuracy: 0.9173 - val_loss: 0.1367 - val_accuracy: 0.9601\n",
            "Epoch 244/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2431 - accuracy: 0.9229 - val_loss: 0.1419 - val_accuracy: 0.9543\n",
            "Epoch 245/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2799 - accuracy: 0.9110 - val_loss: 0.1577 - val_accuracy: 0.9549\n",
            "Epoch 246/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2476 - accuracy: 0.9198 - val_loss: 0.1460 - val_accuracy: 0.9555\n",
            "Epoch 247/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2556 - accuracy: 0.9205 - val_loss: 0.1462 - val_accuracy: 0.9578\n",
            "Epoch 248/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2519 - accuracy: 0.9208 - val_loss: 0.1597 - val_accuracy: 0.9526\n",
            "Epoch 249/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2399 - accuracy: 0.9220 - val_loss: 0.1537 - val_accuracy: 0.9474\n",
            "Epoch 250/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2852 - accuracy: 0.9112 - val_loss: 0.1874 - val_accuracy: 0.9457\n",
            "Epoch 251/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2506 - accuracy: 0.9151 - val_loss: 0.1569 - val_accuracy: 0.9538\n",
            "Epoch 252/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2432 - accuracy: 0.9200 - val_loss: 0.1344 - val_accuracy: 0.9572\n",
            "Epoch 253/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2560 - accuracy: 0.9154 - val_loss: 0.1434 - val_accuracy: 0.9578\n",
            "Epoch 254/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2527 - accuracy: 0.9188 - val_loss: 0.1522 - val_accuracy: 0.9509\n",
            "Epoch 255/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2596 - accuracy: 0.9203 - val_loss: 0.1757 - val_accuracy: 0.9462\n",
            "Epoch 256/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2634 - accuracy: 0.9166 - val_loss: 0.1548 - val_accuracy: 0.9555\n",
            "Epoch 257/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2397 - accuracy: 0.9227 - val_loss: 0.1468 - val_accuracy: 0.9555\n",
            "Epoch 258/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2606 - accuracy: 0.9161 - val_loss: 0.1379 - val_accuracy: 0.9549\n",
            "Epoch 259/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2521 - accuracy: 0.9190 - val_loss: 0.1496 - val_accuracy: 0.9555\n",
            "Epoch 260/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2404 - accuracy: 0.9273 - val_loss: 0.1319 - val_accuracy: 0.9526\n",
            "Epoch 261/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2449 - accuracy: 0.9229 - val_loss: 0.1713 - val_accuracy: 0.9514\n",
            "Epoch 262/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2709 - accuracy: 0.9181 - val_loss: 0.1643 - val_accuracy: 0.9457\n",
            "Epoch 263/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2409 - accuracy: 0.9227 - val_loss: 0.1464 - val_accuracy: 0.9601\n",
            "Epoch 264/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2506 - accuracy: 0.9173 - val_loss: 0.1435 - val_accuracy: 0.9555\n",
            "Epoch 265/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2449 - accuracy: 0.9210 - val_loss: 0.1411 - val_accuracy: 0.9584\n",
            "Epoch 266/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2568 - accuracy: 0.9195 - val_loss: 0.1679 - val_accuracy: 0.9445\n",
            "Epoch 267/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2311 - accuracy: 0.9256 - val_loss: 0.1381 - val_accuracy: 0.9497\n",
            "Epoch 268/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2422 - accuracy: 0.9200 - val_loss: 0.1689 - val_accuracy: 0.9480\n",
            "Epoch 269/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2713 - accuracy: 0.9156 - val_loss: 0.1788 - val_accuracy: 0.9457\n",
            "Epoch 270/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2978 - accuracy: 0.9115 - val_loss: 0.1753 - val_accuracy: 0.9445\n",
            "Epoch 271/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2683 - accuracy: 0.9147 - val_loss: 0.1695 - val_accuracy: 0.9584\n",
            "Epoch 272/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2733 - accuracy: 0.9188 - val_loss: 0.1671 - val_accuracy: 0.9468\n",
            "Epoch 273/500\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 0.2696 - accuracy: 0.9193 - val_loss: 0.1493 - val_accuracy: 0.9590\n",
            "Epoch 274/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2651 - accuracy: 0.9108 - val_loss: 0.1540 - val_accuracy: 0.9532\n",
            "Epoch 275/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2599 - accuracy: 0.9137 - val_loss: 0.1418 - val_accuracy: 0.9555\n",
            "Epoch 276/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2443 - accuracy: 0.9222 - val_loss: 0.1505 - val_accuracy: 0.9509\n",
            "Epoch 277/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2614 - accuracy: 0.9149 - val_loss: 0.1581 - val_accuracy: 0.9514\n",
            "Epoch 278/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2874 - accuracy: 0.9117 - val_loss: 0.1749 - val_accuracy: 0.9503\n",
            "Epoch 279/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2454 - accuracy: 0.9186 - val_loss: 0.1603 - val_accuracy: 0.9503\n",
            "Epoch 280/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2490 - accuracy: 0.9205 - val_loss: 0.1501 - val_accuracy: 0.9532\n",
            "Epoch 281/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2643 - accuracy: 0.9171 - val_loss: 0.1589 - val_accuracy: 0.9503\n",
            "Epoch 282/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.3291 - accuracy: 0.8956 - val_loss: 0.1494 - val_accuracy: 0.9509\n",
            "Epoch 283/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2715 - accuracy: 0.9134 - val_loss: 0.1413 - val_accuracy: 0.9584\n",
            "Epoch 284/500\n",
            "65/65 [==============================] - 4s 67ms/step - loss: 0.2716 - accuracy: 0.9112 - val_loss: 0.1455 - val_accuracy: 0.9543\n",
            "Epoch 285/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2406 - accuracy: 0.9278 - val_loss: 0.1566 - val_accuracy: 0.9543\n",
            "Epoch 286/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2364 - accuracy: 0.9266 - val_loss: 0.1407 - val_accuracy: 0.9561\n",
            "Epoch 287/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2403 - accuracy: 0.9239 - val_loss: 0.1437 - val_accuracy: 0.9491\n",
            "Epoch 288/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2626 - accuracy: 0.9215 - val_loss: 0.1438 - val_accuracy: 0.9514\n",
            "Epoch 289/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2621 - accuracy: 0.9186 - val_loss: 0.1296 - val_accuracy: 0.9566\n",
            "Epoch 290/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2459 - accuracy: 0.9244 - val_loss: 0.1399 - val_accuracy: 0.9561\n",
            "Epoch 291/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2525 - accuracy: 0.9212 - val_loss: 0.1510 - val_accuracy: 0.9538\n",
            "Epoch 292/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2364 - accuracy: 0.9229 - val_loss: 0.1291 - val_accuracy: 0.9590\n",
            "Epoch 293/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2477 - accuracy: 0.9220 - val_loss: 0.1449 - val_accuracy: 0.9555\n",
            "Epoch 294/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2493 - accuracy: 0.9181 - val_loss: 0.1661 - val_accuracy: 0.9532\n",
            "Epoch 295/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2555 - accuracy: 0.9154 - val_loss: 0.1819 - val_accuracy: 0.9451\n",
            "Epoch 296/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2407 - accuracy: 0.9193 - val_loss: 0.1530 - val_accuracy: 0.9491\n",
            "Epoch 297/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2507 - accuracy: 0.9166 - val_loss: 0.1840 - val_accuracy: 0.9474\n",
            "Epoch 298/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2454 - accuracy: 0.9188 - val_loss: 0.1772 - val_accuracy: 0.9474\n",
            "Epoch 299/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2446 - accuracy: 0.9198 - val_loss: 0.1585 - val_accuracy: 0.9462\n",
            "Epoch 300/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2234 - accuracy: 0.9300 - val_loss: 0.1600 - val_accuracy: 0.9514\n",
            "Epoch 301/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2249 - accuracy: 0.9259 - val_loss: 0.1333 - val_accuracy: 0.9538\n",
            "Epoch 302/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2546 - accuracy: 0.9234 - val_loss: 0.1540 - val_accuracy: 0.9538\n",
            "Epoch 303/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2623 - accuracy: 0.9210 - val_loss: 0.1457 - val_accuracy: 0.9532\n",
            "Epoch 304/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2568 - accuracy: 0.9164 - val_loss: 0.1378 - val_accuracy: 0.9509\n",
            "Epoch 305/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2406 - accuracy: 0.9229 - val_loss: 0.1564 - val_accuracy: 0.9509\n",
            "Epoch 306/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2349 - accuracy: 0.9286 - val_loss: 0.1463 - val_accuracy: 0.9561\n",
            "Epoch 307/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2828 - accuracy: 0.9086 - val_loss: 0.1476 - val_accuracy: 0.9561\n",
            "Epoch 308/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2531 - accuracy: 0.9247 - val_loss: 0.1600 - val_accuracy: 0.9526\n",
            "Epoch 309/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2451 - accuracy: 0.9234 - val_loss: 0.1418 - val_accuracy: 0.9532\n",
            "Epoch 310/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2467 - accuracy: 0.9271 - val_loss: 0.1678 - val_accuracy: 0.9462\n",
            "Epoch 311/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2559 - accuracy: 0.9242 - val_loss: 0.1537 - val_accuracy: 0.9503\n",
            "Epoch 312/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2384 - accuracy: 0.9225 - val_loss: 0.1560 - val_accuracy: 0.9538\n",
            "Epoch 313/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2541 - accuracy: 0.9178 - val_loss: 0.1429 - val_accuracy: 0.9543\n",
            "Epoch 314/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2321 - accuracy: 0.9256 - val_loss: 0.1488 - val_accuracy: 0.9526\n",
            "Epoch 315/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2643 - accuracy: 0.9168 - val_loss: 0.1608 - val_accuracy: 0.9474\n",
            "Epoch 316/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2409 - accuracy: 0.9242 - val_loss: 0.1618 - val_accuracy: 0.9503\n",
            "Epoch 317/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2656 - accuracy: 0.9149 - val_loss: 0.1579 - val_accuracy: 0.9503\n",
            "Epoch 318/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2560 - accuracy: 0.9195 - val_loss: 0.1767 - val_accuracy: 0.9543\n",
            "Epoch 319/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2326 - accuracy: 0.9290 - val_loss: 0.1546 - val_accuracy: 0.9572\n",
            "Epoch 320/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2348 - accuracy: 0.9290 - val_loss: 0.1377 - val_accuracy: 0.9509\n",
            "Epoch 321/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2313 - accuracy: 0.9254 - val_loss: 0.1503 - val_accuracy: 0.9526\n",
            "Epoch 322/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2574 - accuracy: 0.9195 - val_loss: 0.1646 - val_accuracy: 0.9491\n",
            "Epoch 323/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2262 - accuracy: 0.9305 - val_loss: 0.1631 - val_accuracy: 0.9428\n",
            "Epoch 324/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2225 - accuracy: 0.9244 - val_loss: 0.1609 - val_accuracy: 0.9503\n",
            "Epoch 325/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2518 - accuracy: 0.9200 - val_loss: 0.1490 - val_accuracy: 0.9538\n",
            "Epoch 326/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2559 - accuracy: 0.9151 - val_loss: 0.1408 - val_accuracy: 0.9584\n",
            "Epoch 327/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2284 - accuracy: 0.9264 - val_loss: 0.1499 - val_accuracy: 0.9578\n",
            "Epoch 328/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2567 - accuracy: 0.9181 - val_loss: 0.1397 - val_accuracy: 0.9561\n",
            "Epoch 329/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2449 - accuracy: 0.9247 - val_loss: 0.1571 - val_accuracy: 0.9526\n",
            "Epoch 330/500\n",
            "65/65 [==============================] - 4s 70ms/step - loss: 0.2735 - accuracy: 0.9132 - val_loss: 0.1598 - val_accuracy: 0.9532\n",
            "Epoch 331/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2377 - accuracy: 0.9298 - val_loss: 0.1539 - val_accuracy: 0.9578\n",
            "Epoch 332/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2321 - accuracy: 0.9268 - val_loss: 0.1514 - val_accuracy: 0.9549\n",
            "Epoch 333/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2588 - accuracy: 0.9188 - val_loss: 0.1430 - val_accuracy: 0.9532\n",
            "Epoch 334/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2447 - accuracy: 0.9244 - val_loss: 0.1481 - val_accuracy: 0.9595\n",
            "Epoch 335/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2422 - accuracy: 0.9217 - val_loss: 0.1550 - val_accuracy: 0.9543\n",
            "Epoch 336/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2448 - accuracy: 0.9210 - val_loss: 0.1455 - val_accuracy: 0.9561\n",
            "Epoch 337/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2541 - accuracy: 0.9176 - val_loss: 0.1298 - val_accuracy: 0.9584\n",
            "Epoch 338/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2399 - accuracy: 0.9247 - val_loss: 0.1584 - val_accuracy: 0.9503\n",
            "Epoch 339/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2553 - accuracy: 0.9195 - val_loss: 0.1322 - val_accuracy: 0.9590\n",
            "Epoch 340/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2671 - accuracy: 0.9164 - val_loss: 0.1690 - val_accuracy: 0.9514\n",
            "Epoch 341/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2428 - accuracy: 0.9239 - val_loss: 0.1624 - val_accuracy: 0.9532\n",
            "Epoch 342/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2664 - accuracy: 0.9190 - val_loss: 0.1500 - val_accuracy: 0.9526\n",
            "Epoch 343/500\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 0.2498 - accuracy: 0.9171 - val_loss: 0.1624 - val_accuracy: 0.9520\n",
            "Epoch 344/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2562 - accuracy: 0.9190 - val_loss: 0.1561 - val_accuracy: 0.9526\n",
            "Epoch 345/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2392 - accuracy: 0.9268 - val_loss: 0.1611 - val_accuracy: 0.9514\n",
            "Epoch 346/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2514 - accuracy: 0.9173 - val_loss: 0.1490 - val_accuracy: 0.9503\n",
            "Epoch 347/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2478 - accuracy: 0.9227 - val_loss: 0.1547 - val_accuracy: 0.9543\n",
            "Epoch 348/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2412 - accuracy: 0.9212 - val_loss: 0.1597 - val_accuracy: 0.9491\n",
            "Epoch 349/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2646 - accuracy: 0.9159 - val_loss: 0.1469 - val_accuracy: 0.9520\n",
            "Epoch 350/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2522 - accuracy: 0.9198 - val_loss: 0.1542 - val_accuracy: 0.9474\n",
            "Epoch 351/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2511 - accuracy: 0.9225 - val_loss: 0.1152 - val_accuracy: 0.9607\n",
            "Epoch 352/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2299 - accuracy: 0.9273 - val_loss: 0.1603 - val_accuracy: 0.9462\n",
            "Epoch 353/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2199 - accuracy: 0.9307 - val_loss: 0.1460 - val_accuracy: 0.9520\n",
            "Epoch 354/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2491 - accuracy: 0.9186 - val_loss: 0.1251 - val_accuracy: 0.9584\n",
            "Epoch 355/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2478 - accuracy: 0.9237 - val_loss: 0.1361 - val_accuracy: 0.9566\n",
            "Epoch 356/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2511 - accuracy: 0.9198 - val_loss: 0.1632 - val_accuracy: 0.9520\n",
            "Epoch 357/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2485 - accuracy: 0.9242 - val_loss: 0.1299 - val_accuracy: 0.9595\n",
            "Epoch 358/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2164 - accuracy: 0.9293 - val_loss: 0.1270 - val_accuracy: 0.9572\n",
            "Epoch 359/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2317 - accuracy: 0.9254 - val_loss: 0.1274 - val_accuracy: 0.9595\n",
            "Epoch 360/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2247 - accuracy: 0.9310 - val_loss: 0.1408 - val_accuracy: 0.9584\n",
            "Epoch 361/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2297 - accuracy: 0.9259 - val_loss: 0.1443 - val_accuracy: 0.9532\n",
            "Epoch 362/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2562 - accuracy: 0.9227 - val_loss: 0.1338 - val_accuracy: 0.9538\n",
            "Epoch 363/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2424 - accuracy: 0.9176 - val_loss: 0.1350 - val_accuracy: 0.9561\n",
            "Epoch 364/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2456 - accuracy: 0.9264 - val_loss: 0.1615 - val_accuracy: 0.9497\n",
            "Epoch 365/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2372 - accuracy: 0.9254 - val_loss: 0.1248 - val_accuracy: 0.9572\n",
            "Epoch 366/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2217 - accuracy: 0.9242 - val_loss: 0.1386 - val_accuracy: 0.9561\n",
            "Epoch 367/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2397 - accuracy: 0.9247 - val_loss: 0.1495 - val_accuracy: 0.9532\n",
            "Epoch 368/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2476 - accuracy: 0.9261 - val_loss: 0.1255 - val_accuracy: 0.9607\n",
            "Epoch 369/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2439 - accuracy: 0.9215 - val_loss: 0.1508 - val_accuracy: 0.9520\n",
            "Epoch 370/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2219 - accuracy: 0.9264 - val_loss: 0.1715 - val_accuracy: 0.9439\n",
            "Epoch 371/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2461 - accuracy: 0.9151 - val_loss: 0.1274 - val_accuracy: 0.9613\n",
            "Epoch 372/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2485 - accuracy: 0.9193 - val_loss: 0.1872 - val_accuracy: 0.9439\n",
            "Epoch 373/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2836 - accuracy: 0.9120 - val_loss: 0.1610 - val_accuracy: 0.9480\n",
            "Epoch 374/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2335 - accuracy: 0.9273 - val_loss: 0.1499 - val_accuracy: 0.9526\n",
            "Epoch 375/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2721 - accuracy: 0.9134 - val_loss: 0.1492 - val_accuracy: 0.9538\n",
            "Epoch 376/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2608 - accuracy: 0.9166 - val_loss: 0.1623 - val_accuracy: 0.9509\n",
            "Epoch 377/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2469 - accuracy: 0.9234 - val_loss: 0.1450 - val_accuracy: 0.9532\n",
            "Epoch 378/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2520 - accuracy: 0.9188 - val_loss: 0.1403 - val_accuracy: 0.9532\n",
            "Epoch 379/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2249 - accuracy: 0.9295 - val_loss: 0.1620 - val_accuracy: 0.9526\n",
            "Epoch 380/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2623 - accuracy: 0.9137 - val_loss: 0.1383 - val_accuracy: 0.9578\n",
            "Epoch 381/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2433 - accuracy: 0.9176 - val_loss: 0.1326 - val_accuracy: 0.9549\n",
            "Epoch 382/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2469 - accuracy: 0.9247 - val_loss: 0.1535 - val_accuracy: 0.9480\n",
            "Epoch 383/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2469 - accuracy: 0.9229 - val_loss: 0.1545 - val_accuracy: 0.9561\n",
            "Epoch 384/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2339 - accuracy: 0.9242 - val_loss: 0.1483 - val_accuracy: 0.9532\n",
            "Epoch 385/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2028 - accuracy: 0.9298 - val_loss: 0.1464 - val_accuracy: 0.9549\n",
            "Epoch 386/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2241 - accuracy: 0.9227 - val_loss: 0.1562 - val_accuracy: 0.9532\n",
            "Epoch 387/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2392 - accuracy: 0.9273 - val_loss: 0.1332 - val_accuracy: 0.9624\n",
            "Epoch 388/500\n",
            "65/65 [==============================] - 4s 68ms/step - loss: 0.2565 - accuracy: 0.9186 - val_loss: 0.1468 - val_accuracy: 0.9613\n",
            "Epoch 389/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2215 - accuracy: 0.9254 - val_loss: 0.1421 - val_accuracy: 0.9613\n",
            "Epoch 390/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2352 - accuracy: 0.9290 - val_loss: 0.1549 - val_accuracy: 0.9549\n",
            "Epoch 391/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2704 - accuracy: 0.9142 - val_loss: 0.1455 - val_accuracy: 0.9538\n",
            "Epoch 392/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2491 - accuracy: 0.9208 - val_loss: 0.1480 - val_accuracy: 0.9526\n",
            "Epoch 393/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2457 - accuracy: 0.9234 - val_loss: 0.1480 - val_accuracy: 0.9526\n",
            "Epoch 394/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2415 - accuracy: 0.9247 - val_loss: 0.1608 - val_accuracy: 0.9514\n",
            "Epoch 395/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2378 - accuracy: 0.9237 - val_loss: 0.1499 - val_accuracy: 0.9555\n",
            "Epoch 396/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2303 - accuracy: 0.9293 - val_loss: 0.1561 - val_accuracy: 0.9595\n",
            "Epoch 397/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2314 - accuracy: 0.9222 - val_loss: 0.1369 - val_accuracy: 0.9590\n",
            "Epoch 398/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2452 - accuracy: 0.9203 - val_loss: 0.1431 - val_accuracy: 0.9572\n",
            "Epoch 399/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2439 - accuracy: 0.9208 - val_loss: 0.1519 - val_accuracy: 0.9538\n",
            "Epoch 400/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2347 - accuracy: 0.9266 - val_loss: 0.1616 - val_accuracy: 0.9514\n",
            "Epoch 401/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2352 - accuracy: 0.9278 - val_loss: 0.1490 - val_accuracy: 0.9572\n",
            "Epoch 402/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2390 - accuracy: 0.9244 - val_loss: 0.1441 - val_accuracy: 0.9613\n",
            "Epoch 403/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2038 - accuracy: 0.9337 - val_loss: 0.1412 - val_accuracy: 0.9514\n",
            "Epoch 404/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2447 - accuracy: 0.9222 - val_loss: 0.1460 - val_accuracy: 0.9566\n",
            "Epoch 405/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2152 - accuracy: 0.9268 - val_loss: 0.1437 - val_accuracy: 0.9561\n",
            "Epoch 406/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2452 - accuracy: 0.9212 - val_loss: 0.1758 - val_accuracy: 0.9474\n",
            "Epoch 407/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2388 - accuracy: 0.9286 - val_loss: 0.1478 - val_accuracy: 0.9514\n",
            "Epoch 408/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2414 - accuracy: 0.9215 - val_loss: 0.1412 - val_accuracy: 0.9601\n",
            "Epoch 409/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2507 - accuracy: 0.9159 - val_loss: 0.1480 - val_accuracy: 0.9584\n",
            "Epoch 410/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2500 - accuracy: 0.9234 - val_loss: 0.1538 - val_accuracy: 0.9549\n",
            "Epoch 411/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2477 - accuracy: 0.9222 - val_loss: 0.1521 - val_accuracy: 0.9503\n",
            "Epoch 412/500\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 0.2382 - accuracy: 0.9264 - val_loss: 0.1632 - val_accuracy: 0.9590\n",
            "Epoch 413/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2178 - accuracy: 0.9317 - val_loss: 0.1388 - val_accuracy: 0.9642\n",
            "Epoch 414/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2266 - accuracy: 0.9268 - val_loss: 0.1603 - val_accuracy: 0.9474\n",
            "Epoch 415/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2189 - accuracy: 0.9320 - val_loss: 0.1498 - val_accuracy: 0.9555\n",
            "Epoch 416/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2296 - accuracy: 0.9261 - val_loss: 0.1392 - val_accuracy: 0.9572\n",
            "Epoch 417/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2301 - accuracy: 0.9239 - val_loss: 0.1519 - val_accuracy: 0.9532\n",
            "Epoch 418/500\n",
            "65/65 [==============================] - 5s 73ms/step - loss: 0.2448 - accuracy: 0.9225 - val_loss: 0.1767 - val_accuracy: 0.9526\n",
            "Epoch 419/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2222 - accuracy: 0.9283 - val_loss: 0.1586 - val_accuracy: 0.9434\n",
            "Epoch 420/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2295 - accuracy: 0.9261 - val_loss: 0.1328 - val_accuracy: 0.9561\n",
            "Epoch 421/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2427 - accuracy: 0.9210 - val_loss: 0.1370 - val_accuracy: 0.9566\n",
            "Epoch 422/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2239 - accuracy: 0.9293 - val_loss: 0.1533 - val_accuracy: 0.9480\n",
            "Epoch 423/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2467 - accuracy: 0.9293 - val_loss: 0.1275 - val_accuracy: 0.9601\n",
            "Epoch 424/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2359 - accuracy: 0.9242 - val_loss: 0.1345 - val_accuracy: 0.9578\n",
            "Epoch 425/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2335 - accuracy: 0.9232 - val_loss: 0.1484 - val_accuracy: 0.9561\n",
            "Epoch 426/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2248 - accuracy: 0.9264 - val_loss: 0.1460 - val_accuracy: 0.9555\n",
            "Epoch 427/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2261 - accuracy: 0.9295 - val_loss: 0.1571 - val_accuracy: 0.9514\n",
            "Epoch 428/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2458 - accuracy: 0.9166 - val_loss: 0.1486 - val_accuracy: 0.9497\n",
            "Epoch 429/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2136 - accuracy: 0.9261 - val_loss: 0.1302 - val_accuracy: 0.9561\n",
            "Epoch 430/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2211 - accuracy: 0.9310 - val_loss: 0.1475 - val_accuracy: 0.9543\n",
            "Epoch 431/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2243 - accuracy: 0.9295 - val_loss: 0.1637 - val_accuracy: 0.9486\n",
            "Epoch 432/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2385 - accuracy: 0.9198 - val_loss: 0.1616 - val_accuracy: 0.9526\n",
            "Epoch 433/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2395 - accuracy: 0.9225 - val_loss: 0.1549 - val_accuracy: 0.9532\n",
            "Epoch 434/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2367 - accuracy: 0.9268 - val_loss: 0.1424 - val_accuracy: 0.9538\n",
            "Epoch 435/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2324 - accuracy: 0.9256 - val_loss: 0.1442 - val_accuracy: 0.9514\n",
            "Epoch 436/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2408 - accuracy: 0.9254 - val_loss: 0.1378 - val_accuracy: 0.9590\n",
            "Epoch 437/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2219 - accuracy: 0.9371 - val_loss: 0.1491 - val_accuracy: 0.9578\n",
            "Epoch 438/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2276 - accuracy: 0.9327 - val_loss: 0.1387 - val_accuracy: 0.9566\n",
            "Epoch 439/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2230 - accuracy: 0.9232 - val_loss: 0.1745 - val_accuracy: 0.9480\n",
            "Epoch 440/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2177 - accuracy: 0.9307 - val_loss: 0.1479 - val_accuracy: 0.9566\n",
            "Epoch 441/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2348 - accuracy: 0.9261 - val_loss: 0.1480 - val_accuracy: 0.9555\n",
            "Epoch 442/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2277 - accuracy: 0.9264 - val_loss: 0.1314 - val_accuracy: 0.9590\n",
            "Epoch 443/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2407 - accuracy: 0.9181 - val_loss: 0.1465 - val_accuracy: 0.9509\n",
            "Epoch 444/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2474 - accuracy: 0.9242 - val_loss: 0.1471 - val_accuracy: 0.9566\n",
            "Epoch 445/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2317 - accuracy: 0.9251 - val_loss: 0.1633 - val_accuracy: 0.9572\n",
            "Epoch 446/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2225 - accuracy: 0.9249 - val_loss: 0.1287 - val_accuracy: 0.9607\n",
            "Epoch 447/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2551 - accuracy: 0.9181 - val_loss: 0.1262 - val_accuracy: 0.9601\n",
            "Epoch 448/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2854 - accuracy: 0.9134 - val_loss: 0.1847 - val_accuracy: 0.9457\n",
            "Epoch 449/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2611 - accuracy: 0.9147 - val_loss: 0.1555 - val_accuracy: 0.9538\n",
            "Epoch 450/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2309 - accuracy: 0.9242 - val_loss: 0.1492 - val_accuracy: 0.9532\n",
            "Epoch 451/500\n",
            "65/65 [==============================] - 5s 73ms/step - loss: 0.2343 - accuracy: 0.9256 - val_loss: 0.1525 - val_accuracy: 0.9555\n",
            "Epoch 452/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2257 - accuracy: 0.9278 - val_loss: 0.1531 - val_accuracy: 0.9503\n",
            "Epoch 453/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2236 - accuracy: 0.9278 - val_loss: 0.1400 - val_accuracy: 0.9584\n",
            "Epoch 454/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2173 - accuracy: 0.9298 - val_loss: 0.1329 - val_accuracy: 0.9607\n",
            "Epoch 455/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2453 - accuracy: 0.9234 - val_loss: 0.1462 - val_accuracy: 0.9538\n",
            "Epoch 456/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2405 - accuracy: 0.9249 - val_loss: 0.1425 - val_accuracy: 0.9578\n",
            "Epoch 457/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2354 - accuracy: 0.9242 - val_loss: 0.1493 - val_accuracy: 0.9584\n",
            "Epoch 458/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2322 - accuracy: 0.9268 - val_loss: 0.1190 - val_accuracy: 0.9566\n",
            "Epoch 459/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2462 - accuracy: 0.9237 - val_loss: 0.1312 - val_accuracy: 0.9584\n",
            "Epoch 460/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2193 - accuracy: 0.9320 - val_loss: 0.1404 - val_accuracy: 0.9538\n",
            "Epoch 461/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2344 - accuracy: 0.9273 - val_loss: 0.1504 - val_accuracy: 0.9497\n",
            "Epoch 462/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2498 - accuracy: 0.9195 - val_loss: 0.1889 - val_accuracy: 0.9457\n",
            "Epoch 463/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2428 - accuracy: 0.9229 - val_loss: 0.1478 - val_accuracy: 0.9549\n",
            "Epoch 464/500\n",
            "65/65 [==============================] - 5s 73ms/step - loss: 0.2244 - accuracy: 0.9259 - val_loss: 0.1304 - val_accuracy: 0.9584\n",
            "Epoch 465/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2187 - accuracy: 0.9310 - val_loss: 0.1300 - val_accuracy: 0.9595\n",
            "Epoch 466/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2488 - accuracy: 0.9212 - val_loss: 0.1735 - val_accuracy: 0.9457\n",
            "Epoch 467/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2249 - accuracy: 0.9281 - val_loss: 0.1464 - val_accuracy: 0.9543\n",
            "Epoch 468/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2066 - accuracy: 0.9305 - val_loss: 0.1493 - val_accuracy: 0.9509\n",
            "Epoch 469/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2305 - accuracy: 0.9249 - val_loss: 0.1449 - val_accuracy: 0.9636\n",
            "Epoch 470/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2218 - accuracy: 0.9359 - val_loss: 0.1506 - val_accuracy: 0.9532\n",
            "Epoch 471/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2807 - accuracy: 0.9117 - val_loss: 0.1989 - val_accuracy: 0.9410\n",
            "Epoch 472/500\n",
            "65/65 [==============================] - 4s 69ms/step - loss: 0.2960 - accuracy: 0.9076 - val_loss: 0.1726 - val_accuracy: 0.9474\n",
            "Epoch 473/500\n",
            "65/65 [==============================] - 5s 69ms/step - loss: 0.2398 - accuracy: 0.9256 - val_loss: 0.1393 - val_accuracy: 0.9613\n",
            "Epoch 474/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2365 - accuracy: 0.9293 - val_loss: 0.1412 - val_accuracy: 0.9543\n",
            "Epoch 475/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2222 - accuracy: 0.9300 - val_loss: 0.1417 - val_accuracy: 0.9509\n",
            "Epoch 476/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2387 - accuracy: 0.9254 - val_loss: 0.1520 - val_accuracy: 0.9520\n",
            "Epoch 477/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2243 - accuracy: 0.9261 - val_loss: 0.1560 - val_accuracy: 0.9543\n",
            "Epoch 478/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2585 - accuracy: 0.9188 - val_loss: 0.1866 - val_accuracy: 0.9491\n",
            "Epoch 479/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2172 - accuracy: 0.9293 - val_loss: 0.1367 - val_accuracy: 0.9590\n",
            "Epoch 480/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2128 - accuracy: 0.9310 - val_loss: 0.1563 - val_accuracy: 0.9584\n",
            "Epoch 481/500\n",
            "65/65 [==============================] - 6s 88ms/step - loss: 0.2519 - accuracy: 0.9261 - val_loss: 0.1612 - val_accuracy: 0.9445\n",
            "Epoch 482/500\n",
            "65/65 [==============================] - 5s 74ms/step - loss: 0.2426 - accuracy: 0.9237 - val_loss: 0.1422 - val_accuracy: 0.9578\n",
            "Epoch 483/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2306 - accuracy: 0.9261 - val_loss: 0.1522 - val_accuracy: 0.9555\n",
            "Epoch 484/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.1679 - val_accuracy: 0.9480\n",
            "Epoch 485/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2392 - accuracy: 0.9261 - val_loss: 0.1632 - val_accuracy: 0.9491\n",
            "Epoch 486/500\n",
            "65/65 [==============================] - 5s 70ms/step - loss: 0.2283 - accuracy: 0.9266 - val_loss: 0.1354 - val_accuracy: 0.9601\n",
            "Epoch 487/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2311 - accuracy: 0.9266 - val_loss: 0.1309 - val_accuracy: 0.9642\n",
            "Epoch 488/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2384 - accuracy: 0.9259 - val_loss: 0.1589 - val_accuracy: 0.9543\n",
            "Epoch 489/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2178 - accuracy: 0.9349 - val_loss: 0.1381 - val_accuracy: 0.9549\n",
            "Epoch 490/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2315 - accuracy: 0.9259 - val_loss: 0.1594 - val_accuracy: 0.9532\n",
            "Epoch 491/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2181 - accuracy: 0.9317 - val_loss: 0.1575 - val_accuracy: 0.9509\n",
            "Epoch 492/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2200 - accuracy: 0.9325 - val_loss: 0.1438 - val_accuracy: 0.9584\n",
            "Epoch 493/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2237 - accuracy: 0.9298 - val_loss: 0.1314 - val_accuracy: 0.9543\n",
            "Epoch 494/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2258 - accuracy: 0.9281 - val_loss: 0.1453 - val_accuracy: 0.9549\n",
            "Epoch 495/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2181 - accuracy: 0.9288 - val_loss: 0.1384 - val_accuracy: 0.9578\n",
            "Epoch 496/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.3076 - accuracy: 0.9039 - val_loss: 0.1624 - val_accuracy: 0.9526\n",
            "Epoch 497/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2406 - accuracy: 0.9244 - val_loss: 0.1656 - val_accuracy: 0.9451\n",
            "Epoch 498/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2264 - accuracy: 0.9234 - val_loss: 0.1657 - val_accuracy: 0.9497\n",
            "Epoch 499/500\n",
            "65/65 [==============================] - 5s 71ms/step - loss: 0.2369 - accuracy: 0.9273 - val_loss: 0.1294 - val_accuracy: 0.9618\n",
            "Epoch 500/500\n",
            "65/65 [==============================] - 5s 72ms/step - loss: 0.2381 - accuracy: 0.9251 - val_loss: 0.1579 - val_accuracy: 0.9595\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=500, validation_data = validation_generator, verbose = 1, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show the progress after training, run this code below."
      ],
      "metadata": {
        "id": "Qy0TFOLvZwaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "E2II48ecgI2z",
        "outputId": "e694fd3e-aa86-4736-f6f4-08b1f7ac4e24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5hURdbG35oZJjCJJFmCiigmlGBgVYxgZEVdxYiuWczomjDnxVV3dd3FAAu6nxjWjJgxr4KirBgRyRIcGJgBJjH3++P0sc6trnv7dk9Prt/z9NPdN9ZNb5176tQp5XkeHA6Hw9FyyWjsAjgcDoejfnFC73A4HC0cJ/QOh8PRwnFC73A4HC0cJ/QOh8PRwnFC73A4HC0cJ/StEKXUa0qp09O9bGOilFqklDq4HrbrKaW2i/3+h1JqQpRlU9jPyUqpN1Itp8MRhnJx9M0DpVS5+NsWQCWALbH/53qe92TDl6rpoJRaBOAsz/PeSvN2PQD9PM9bkK5llVJ9APwMoI3neTXpKKfDEUZWYxfAEQ3P8wr4d5ioKaWynHg4mgrufmwaONdNM0cpNVwptUwp9Sel1EoAk5VS7ZVSryil1iil1sV+9xTrzFJKnRX7PVYp9aFSamJs2Z+VUoeluGxfpdT7SqkypdRbSqmHlFJPBJQ7ShlvVUp9FNveG0qpTmL+qUqpxUqpEqXUdSHnZ0+l1EqlVKaYdoxSal7s91Cl1CdKqVKl1C9KqQeVUtkB25qilLpN/L8yts4KpdSZxrJHKKXmKqU2KKWWKqVuErPfj32XKqXKlVJ787kV6++jlJqtlFof+94n6rlJ8jx3UEpNjh3DOqXUC2LeKKXUl7Fj+EkpNTI23ecmU0rdxNdZKdUn5sL6o1JqCYB3YtOfiV2H9bF7ZCexfp5S6t7Y9Vwfu8fylFKvKqUuMo5nnlLqGNuxOoJxQt8y6AqgA4DeAM4BXdfJsf+9AGwG8GDI+nsC+B5AJwD3AHhMKaVSWPbfAD4D0BHATQBODdlnlDKeBOAMAJ0BZAMYDwBKqQEAHo5tv3tsfz1hwfO8TwFsBHCgsd1/x35vAXBZ7Hj2BnAQgAtCyo1YGUbGynMIgH4AzPaBjQBOA9AOwBEAzldK/T42b7/YdzvP8wo8z/vE2HYHAK8C+Gvs2P4C4FWlVEfjGOLOjYVE53kayBW4U2xb98XKMBTAVABXxo5hPwCLgs6Hhf0B7AhgROz/a6Dz1BnAFwCkq3EigEEA9gHdx1cBqAXwLwCn8EJKqd0A9ACdG0cyeJ7nPs3sA3rgDo79Hg6gCkBuyPIDAawT/2eBXD8AMBbAAjGvLQAPQNdklgWJSA2AtmL+EwCeiHhMtjJeL/5fAGBm7PcNAJ4S8/Jj5+DggG3fBuDx2O9CkAj3Dlj2UgDPi/8egO1iv6cAuC32+3EAd4nltpfLWrZ7P4D7Yr/7xJbNEvPHAvgw9vtUAJ8Z638CYGyic5PMeQbQDSSo7S3L/ZPLG3b/xf7fxNdZHNs2IWVoF1umGFQRbQawm2W5XADrQO0eAFUIf2/o560lfJxF3zJY43leBf9RSrVVSv0z9iq8AeQqaCfdFwYr+YfneZtiPwuSXLY7gLViGgAsDSpwxDKuFL83iTJ1l9v2PG8jgJKgfYGs99FKqRwAowF84Xne4lg5to+5M1bGynEHyLpPhK8MABYbx7enUurdmMtkPYDzIm6Xt73YmLYYZM0yQefGR4LzvDXomq2zrLo1gJ8iltfGb+dGKZWplLor5v7ZAP1m0Cn2ybXtK3ZPTwdwilIqA8AY0BuII0mc0LcMzNCpKwD0B7Cn53lF0K6CIHdMOvgFQAelVFsxbeuQ5etSxl/ktmP77Bi0sOd534CE8jD43TYAuYC+A1mNRQCuTaUMoDcayb8BvARga8/zigH8Q2w3UajbCpCrRdILwPII5TIJO89LQdesnWW9pQC2DdjmRtDbHNPVsow8xpMAjAK5t4pBVj+X4VcAFSH7+heAk0EutU2e4eZyRMMJfcukEPQ6XBrz995Y3zuMWchzANyklMpWSu0N4Kh6KuOzAI5USv0u1nB6CxLfy/8GcAlI6J4xyrEBQLlSagcA50csw9MAxiqlBsQqGrP8hSBruSLm7z5JzFsDcplsE7DtGQC2V0qdpJTKUkqdAGAAgFcils0sh/U8e573C8h3/vdYo20bpRRXBI8BOEMpdZBSKkMp1SN2fgDgSwAnxpYfDOC4CGWoBL11tQW9NXEZakFusL8opbrHrP+9Y29fiAl7LYB74az5lHFC3zK5H0AeyFr6L4CZDbTfk0ENmiUgv/h00ANuI+Uyep43H8CFIPH+BeTHXZZgtf8DNRC+43ner2L6eJAIlwF4JFbmKGV4LXYM7wBYEPuWXADgFqVUGahN4Wmx7iYAtwP4SFG0z17GtksAHAmyxktAjZNHGuWOSqLzfCqAatBbzWpQGwU8z/sM1Nh7H4D1AN6DfsuYALLA1wG4Gf43JBtTQW9UywF8EyuHZDyA/wGYDWAtgLvh16apAHYBtfk4UsB1mHLUG0qp6QC+8zyv3t8oHC0XpdRpAM7xPO93jV2W5oqz6B1pQyk1RCm1bexVfyTIL/tCovUcjiBibrELAExq7LI0Z5zQO9JJV1DoXzkoBvx8z/PmNmqJHM0WpdQIUHvGKiR2DzlCcK4bh8PhaOE4i97hcDhaOE0uqVmnTp28Pn36NHYxHA6Ho1nx+eef/+p53la2eU1O6Pv06YM5c+Y0djEcDoejWaGUMntT/4Zz3TgcDkcLxwm9w+FwtHCc0DscDkcLxwm9w+FwtHCc0DscDkcLxwm9w+FwtHCc0DscDkcLxwm9o9XyySfAV181dikcjvqnyXWYcjgain32oW+X7snR0nEWvcPhcLRwnNA7HA5HC8cJvcPhcLRwnNA7HA5HC8cJvcPhcLRwnNA7HI5mx6uvAu++29ilSI5PPgGefbZx9u3CKx0OR7PjyCPpu7FDYzduBCoqgI4dEy/bmOG8zqJ3OByOFNljD6BTp8YuRWKc0DscDkeK/PBDY5cgGk7oHWll1SrgtdcauxSOps4PPwAfftjYpWg9OB99M8TzAKUauxR2Dj0UmDcPqK4GstJ4dzXlY3Ykzy67AFVVQG1t8te1trZ+ytTY1NYCGfVkejuLvpmxZAndDE880dglsfPdd/RdWZm+bfIxP/lk+rbpaFyqquh7wYLk1924Mb1laQhk5WRrjH35ZSAzE/j22/rZvxP6ZsaXX9L3U081bjmCYIukoiJ92/zmG/qeOjV922zsaI2WysKFwOWXJ7a6e/em79//PnjZuXOBCRPip5eV1a2M9UFFBXD++cCvv9rnl5fr31u2xM+fMYO+3347/WUDIgq9UmqkUup7pdQCpdTVlvm9lVJvK6XmKaVmKaV6inm9lFJvKKW+VUp9o5Tqk77itz5YQHNzG7ccQfBreDoteq480vnK3lJf/9NNSQnw44/Rlv3vf4ETTgDuuy9x+udttqHvb76hdh0bQ4YAt91GbkCJFM10sXJl/HEuWQIsXx5t/enTgX/8A7jySvv80lL92/ZsdOlC30Hnoq4kFHqlVCaAhwAcBmAAgDFKqQHGYhMBTPU8b1cAtwC4U8ybCuDPnuftCGAogNXpKHhrhW+SnJzGLUcQ9WHR14fQ19To3866D2annYDtt0+83H/+A+y9NzBnTrTtSvHetMm+DFu+pjDWh0U/YgQdpyxL795Az57B60j4fgoycBIJ/VZb0XejCT1InBd4nrfQ87wqAE8BGGUsMwDAO7Hf7/L8WIWQ5XnemwDgeV6553kBl9URBb5JmqpFz6KcTouehbi+hF7+ZiZPBgoL7a/ZNubNo7eZqNZvcyGq8Hz/fXLblfdHkNAz7M8//HByj4QJ/UUXAQcckFxZAGD+fPp+7rnk1wX0PWq+fTBS6Pl4JPwm3JhC3wPAUvF/WWya5CsAo2O/jwFQqJTqCGB7AKVKqf8opeYqpf4ce0PwoZQ6Ryk1Ryk1Z82aNckfRSuCLeXGsOg//xx46aXwZerDomdRqC+htz2cF19MLoKoboJ//5u+G6uLe7JMm5ZaDPi//w08/DAwc2b4conekiorgexs+s2Nq7W1wN13x/u5+fq/9hq5R8KuyYMPArNmhe/bBruSVqygb5sYM54HPPSQ362TSOg3b9a/bUYQr1dfQp+uALjxAB5USo0F8D6A5QC2xLa/L4DdASwBMB3AWACPyZU9z5sEYBIADB482L1Ih9CYFv3gwfQd9hCny6IvK6MohLZtdaUhhX79eqrsUj0PiYSeLayNG4Hi4sTby8ujb/lAM6tWAZ07RwsjrKwkC7d9+8TLpornAaedRud240ayNvPyohkPJ5/s347tdxQqK+kYV63SFv28ecDVV1Ogwdy5/mUlUVw31dVAmzbx08vLqayFhfR/zRpKX7Bhg14P0IJvY/ZsYNw4f4ViCn11Nd2j3GtWVhxhQm8rczqIYtEvB7C1+N8zNu03PM9b4XneaM/zdgdwXWxaKcj6/zLm9qkB8AKAPdJS8lZKU2+MTZdFX1SkIzN4W9KN0q4dsNdeqW8/kdAzUUP52ralb9MN8dVXQNeuwOOPR9vOyJFAhw7Rlk0VFh0ua/v25KNOhCnmK1fq3+bbVqJKrbJSHyeXg8X2yy/9+zKt68WLE5f1l1/s0/v2pXsLIIu8c2fgjjv0vvm+WLYseNuffkrf0gDg9fj76qvJ7752bfwx2N4WeNpbbwXvty5EEfrZAPoppfoqpbIBnAjA9wKvlOqklOJtXQPgcbFuO6VUrKkBBwL4pu7Fbr3wa2tT7TzEQv/AA3SzJ2LxYuDgg/0+TObXXykq49RT6b8pJnUZ2DuR0PNxRBV6tujvvVcLwdy5wMCB9Nt0ddTUAEcfrZdl2EpMZwPxtdcC//yn/i8ro8MPp+/33gvfxr33kltF8t//Bi8fxXVjCr28B6RFbVrA8+aFbxsIFmp2C9XUUCgoQA3J/CbG94Jc/4wzgAMPBCZOpP/c4Ny3r16Gj4HX5zDoyZPp27Top08HLrhAT2t0iz5miY8D8DqAbwE87XnefKXULUqpo2OLDQfwvVLqBwBdANweW3cLyK3ztlLqfwAUgEfSfhStCBb6MB9iY8IV0AsvxAsDU1EBPP88icGNN1Ls8H/+Y1923Dj9u7599C+/TA/8Dz/QazdA5/vNN7VltnGjvaxs0QO6YjrnHD3NvF4//0z7O+kke/nYwkwHd94JnHceHcuXX/rdIlHTVYwfD1xzjX+azUfNmI3YH38MLBUtfey6AXRlKoVeNmqbQv/zz/Rt63mdn0/fcl825s3T+5Vvn3xfyLJMmUIpkTl0ko9b3kO8Lb6XdtiBvl99lc65KfQnnkhtHf/7HxkzVVXkqmzUnrGe583wPG97z/O29TyPRfwGz/Neiv1+1vO8frFlzvI8r1Ks+6bnebt6nreL53ljY5E7jhRh/2SYu6ExiXKjTpwIjB4NvPiiFtQgP7g8ThaPqJEwYchtVFdTQ/PRRwOXXQb076/nLVlCaR3GjKH/I0YAxx4b7j5gS1W+dZlCn6gto6Qk2nEkw6xZwO67AwcdlJ7tsdHhefFCb0YyDRsG9Oun/0uht1n00mrnVAkMW/uZcWEd5CYDgq8PVw6ffKLLL4We77cw1+O6dfRtE3ozzPLdd+mcB7ludt2VQliD2hTShesZ28zgm7OuQj9xIgmRrfFQsn49LffQQ3qaUnZXCxBN6LnsxxxDlj+gXR9BywL6YU8UjhcFM7ySKxwzEoUty59+IjH76CP6b0Z+yO1xbvIwoWchCRKUVIX+l19ovxwFJAUy3ZkWy8ro/snIoLcGiS1kVVZqFRXxrhsW0KwsavCU68l1pVtHKeBPf9L/ue0qKMy1c2f6/uQTvT8Z6MflDhN6fruz9QXgaeb1jtIYy1FI9YET+maGtOi3bKGbnH2NyXDPPfTNAhcEP1R/+5t/epDFFEXoOeJBwg+C5wE33aSnS8HgZdKR68R03bB1aAoUx4cXF/vF3axs5EPPlmqY0HMFyw/9jz+Se4RJVejZN/yvf9G3PFfpEvqTTqIGzbIyff+Ywmi7bsyWLfRp147+S4u+oADo3t1/T59zjr/h17Sa+V7+8591PHzQsXI5X35Zu9bKy6nhtKgosUXvefrahAm9KebyetqEvqrKWfQOgRSI++6jm/yKK5LfDlt6id4MWKzMV/OgNoIoQm+Lg+abf8UK4Oab9XQpGPww1bUL/Lp1ZKEzUuhNtxAnaWvXzv+wmm9Cspy2qJkwof/iC+Avf6EGT4atRhuzZwOffWafx+eGK1Pp60+X0P/hD7T9sjKyjG3I8yiv1/z5+n9eHlng0kffvj29ES1ZotdZsIDCQYMoLCRf91VX6Wl8rN9+6xdtPu9mG8iRR1IlY7PoZdhpaak2tsJ89KaYy4rL9uw4143DB99IzzyjG4e4+3Qy8IOYyHXDAm8KfZBvOYrQ2+Kg+cEysxnKiogfprpa9P37kz9e7oOPL0joCwr8Qh9m0fMruDwXQa6b6mpg0KD4CJYgi37jRmDoUGDPPe0NtnxuCwrom5fJytLWbl3JzSVxnTyZ2lpsSBGU13vnnYGzzqLfOTnUiC0t+nbtSOjNqJmw3PWdO8f3aF25ko53wADguONomucF3+9FRSS0Not+xx2poxagG4IB+73Jx21ebyn0QRa9c904foNvJHnDclxwMrCgJYp355vZFPqgByZK2GdZmT9KRZbDtDrlQ8GWYCpCX1kJdOtGDcBm5+s996S3IyBe6Pk4Kyr84vvoo2R9KkUNuLYoHnkuvvwSmDQpfruMFBAgOAuibBtZbckaxcdmCv1229mXT4W8PLv7TRIk9ICOWsrJoSgZm9AnQ3Gxv+L9/e9JNPkN6dVX6ZvF1/a8FBRQZVhTA9x+O4UHMzk5OlggSLATuW6cRe9ICpurJZVQPHbdJLLo+YY1hV6+jv/0k+76HyUEsrw8vucn78cUem4w47KWlCTvunnxReD118nKu+wy+zLPP0/fQRE95eV+oZ81S4vu/ff7r0uQO+zcc/Vv87yboYJBHX7ksdusfhZzrmT43pAx33UlL09XJEFIoTevF98jubnBFn0QNkOivNwvnltvTVa4GW/P59zW6zg/X1v011/vnxck9NLgSCT0suK+//74671hgxN6h8AUkdzccKGvrra7Skyh37TJbt0HuWjkw7vLLsDxx9PvKPH9ZWXxDxvv23xlN6N7fvghsUUvj9nzyMIbNUr/D8Mm9H370vak39wsFwtb1676d9jbjXmuTdEO6vAjryWvU16uryPnSmHh4cbSPn2Cy2Jj/frgSq+uFj2Tk0NuF/bHr1tHQh/WM7h79/hp69bFu87atYuP8+dzxI3AgE4PnJ+vLXqT7Gwt9DI+X4q3dN1s3hwf5CCfo3nz4vezdq1z3TgEptDLPB02jj/e/qpqum4KCnQnD4mMhpHIh1dap2b5bBZ+mEVvHou5fhShHz1aH7OM1oiC7UEfNizeot+yBejVC7j1Vvq/cSMJhfTzmkIvr0OiN6mgDj+mRe95tF2OjWeLns9RKhb9xo0khjJsUZKbm9iiD2qMleTkkNvsiy/o+svG2CBs7VGlpf77rk0bKr+89uvW6XtdCj1b1gUF/mtnlpOFXiYdk4OE8PmurKQyfv11/Ha4M5eNtWudRd/iqaqiTjjffksPyKmnkk/36aeBG27wL2sKUadO4SGSL75on242xnoehUxedBGFnp14IokqC7C536C3BNOi//VXOjb5gJSVkUUoO7zwQxhWaWVmUrhjItfNK6/Q99FHA9tu65+XqA1BClTHjuTz5giTkhL/w5iToy3C5ctpXrJCL33BEmnRV1UBRx1FlbZ8kygpodQFnqejX3i+mT/GJvSff+7/z5U5u8uChquMatGPG0e9ioMs+qwsylfEkUcbNiR23XAcvIQTiDEs9JLSUuCUU+i3nMcN5mzRv/xy/PYLCrTQc0VqWt/yfAcZIkVFeiQpgPIaTZtGv51F38yYOZMezJ9+ShzlMGMG3aSffkoNVGefTVEnTzxBD/UJJ5DF6Hm0bE1NvMXRqVM0Hz1bxl98QaIkXTdSnB98kARy+nRK9sRCb7pwbGJbXR0v9I8+Ssd27bX00K9YQQJTWOj3UwZZ9AC5XaZPpwiKL76wP0jLlvk72QA6pYEkketG5lX/7DM6vwUFJFbl5X6hMYWeLfog1w0L/ezZ2tc7dqyev99+wIUXUjRVaak+xwsWUOX17LN+8Z0yhc4HU1mpRVp2QlLKLvR7GOkFOYeLjNSxkZeXeGzTxYupk92hh1LoqI1Vq2iwEoDaUDyPRJh7t9qwCT3gb2Bn143kuecoDQPgf5vkip199JIePcjweeABvT0WetM6l6mWg8jOJnHndYcM0fePs+ibEZ98Ahx2GInadttRKFkQH34IHHFEfMMPC56s3WfMoGX//OfkXTfmdgcNIn8tC97mzeGZ/li4TZ+yzUqrrqbPTjvpaSx2jz9ODz13gzfLHGbRn3MOxW7vtRdVirKBlo9jm20o7DBdqSGuv17nKC8spPPH0UIcV80+ZkBb9FlZwRY9X4OhQ6lCVYq2zVZl5840nc8fvwVJN44MI/zqKxJ7ZuFCbdGz8JSUkEhJgeT2CpN996XrwNuwpRgAyHXzhz/Y5zEffOAvp40hQ8jn3quXfvNs1y58VKcgoZfhqTaLnl1svA+GK2W26E3++lcS4/x8Oh8s9KbrKkpv7exsuuZbx3IBc5gql8MJfRPkzDPjG41YMKOMMsQP4hdf+DslsYBKoefOPcuXp27RS4tcumEqKoIb/jIz9Xqm0Ad1etqyhUTg/vtpmmlB8wNRU+Ofx/uxuaHYEt5rLxIhmQe8a1faDp8XaeEy++4bPy0R8vzzw/jrrzpSBCChZ+tzyZJwH/3ZZ9N1ktcvN5eW4fQPLB7832yg7tUrvpyy3eDHH7VI//e/NHhKSQkZA5wXvWNHnVDOpLKS9s1ZFcOE/sIL/fdRSQm5+5iwzJbz55Plu/vu9H/vvXWP3mSFnof7k29uNoteGiZyHlv07KMH9P7l8SlF9yGfb1Poo0Sb8T3F7Qxm9JJz3TRBJk8my1I+MMmkGuWcHBs2+IWerVW5Da4U8vPjb74OHWgbtgf3mWf076Domc2bgxv+Nm4Mdt3YLHouZ5s22uqV1jczfDhZ+LLMFRX031ZpsdBzxIW0EFev1n5OgLJhmiQblw34e0Pyw8hCz0Kck0PiW1SkLbIgoW/fno5Nuhh4O/zNFYop9EuX0raGDtXrsiUv2z6WLfPfH3/7mxb6vDwaHezbbxO3U/D5NWP7GX4DkRUB93JlZFvCGWcATz7pX1aW4bbb9O/27cP9/2ZjbF6e/w0SsFv0kkSuG3anmEaVTLwX1rAaBAs53495ef7+JM6ir0fWrQt2XZisXRsfxSFvaH4wbRdswQK//zrIVcHbk7W7FHozjKyoiKwJ26ujfL1ma9tk82adWMzEjE+W2Lroczmzs/U5sI0MOWFCvNVWWUllsZWRhZ4fLvNtYvp0/fv11/3zbr/dnzAtap53KfRyNCLTos/I0AIc5qMvKqJjlINnm0LPFQoLJlupy5aR+LArKS+PcvgDdL74XNoq7LVrtbAcdVR4L+o99wyeB1BOe27QNMnNDR4MZ8gQSmAnl5Vst51+O040mpdp0WdlxW+vTZvwEbrktbW5bvgcmQEIsmypWN+8Dr9deZ6/7M6ir0fGj6cHIApdulDvSol0e7BIS6HnoeH69SPLhpFCz+LmeXahl7lBbEIPxLs8TMGsrLTHyZeVkd93+PD4edKiN7H1spRCzw+NTeiHDKFv06IPckHxMcrXXPmAmPuQvtZrr/ULfdTMl/L8835Xr4636AE9xGJGht9HbzsG6R83BYqX4el8vVasoLcZ9u1WVPiPiV06NhccW/RRmDgxvqKUnHaa/+1JolSw0Hfq5J9nW+6SS+ibRTbIYrYJvTkEYna2PRafO6zJWHzpuuE3FBbiIIs+yKWVKOTUFPqSEv91dBZ9PXH44eRCkAmuwpA1PN+I8uFiK1fmOCkr0w8sp44FtLVWVuaPVbcJPbs/qqv9ZWjTRosDi+Spp9K0HXf0l50rHJNffqFtjhwZPy9M6G2DGHPWSWnRm135d93V/mpeUeH38Up4efnws3ULxAu9aRVKYYnaq9Zm0dfWxlv0gBZS7sZuc93Y4ub5WvJ906OHv7x835SV0TGx5c5j6TLdu9M006IvLo4u9IsWAb/7nd89JMnISDymbND8oiL/ubAJ/YQJ9CzxMa5cScbL2rX+58bsMGUT+jZt4sNqAYoiW77c/2xwxdG2rRZ9nhYk9Dk5dp88C3gQ/ExzxVxb64S+QeDRdUpLkx+xiW+GpUupEWzGDHt+a7MBjpFCL+ez0MtpLASmSEmL/uOPgXfeofC7srL4BmF2jZhwGmJbA9jGjcHnZc0aCveTWQa5IfTII4MtehlqZ1r0PJzdfff5R17iB0AKvQzBM98uzA5i8mFK1FGJsQk94O8sxMtwuSor/a4bKQZ//KMOJWQ4AonfhPga2IS+sJA6RV12GTB1Ku2bxbNDByoTn78nn6TlN22idaMIPYtPu3YUxmqSn5/Yt28K+GGH0Shjhxzin26rEJTSFR1Ax1NURC4Y6YYxfe+yPUhivnkDJNTdu/uXf/ddykGUl6eFPsh1w/vOydHLbrONv+J/7LH4kbgYFvqzzqJKZ/x4f1mc66YBCEr4ZIsNB/Sr4cqVwPbbU/gjC70cGOGXX+xCL90o0s9vdnjhfQDxDaBS6P/4R/vIQY/EBm5ct85u0XM3cdurbnl5sEVfW0ux/jwmKpfvwAPpgbVZ9LIHp4nMIXL00VQhtG/vj5iRQi+tH/O4woQ+jE6dqPyA3XUDkJiZLhYp9FlZJNwcasp07Eix8F266LBMTqTGyLA7IF7oCwvpvIwZ44/Wad/eX8YRI6hXK+8/zO99zz06ORtjG97QTEJnwxT6Pn0odbCZ0TTZ4fKkGObnU1l+/3v6b7Poa2vtlRK7XGQ5+/aliChAC3u7drSfBx/0ry8tehb6m2/W90ObNhSNJ58JCQjtHP4AACAASURBVN9TbdpQZdC2rd/l5Sz6BsDmigDo4evUKb4Rj/9L8WXLW+bY+N3v7GIpLUt+sKTrRvqrueIwhV66boLgCIJDDonvCSm33b59fD6UMNcNI6Nqysv1Q8cWvSyzabHwOVRKn7M33yQrqUsXOp/vv6+Xl0Jvi3nm7QcJ/YEH6vYBGzk5ehu28EqAHkr5wANaZHnwiPnzaT9mBd+hA1XaFRV0v5n9LIJcN+Xldv+vFHoWqfvuo0pFWvFhIn3llfEN69ddFy9WUaJMTKFP1LAaFbldpei+vPBC+h8k9ECwLz3IxcTinZdH55z3wfDxZGfrZXNz/QLO820ETefr6Cz6NHLNNSQmJtKif/hh3ei0apV/JB2ABMoW981iZbor2PoA9NuBzYUgEy9JS5jFmF03UowSPUzygeeegRIW4g4dqCLYZRc9z3TdRHlwbdYJW1emxcJCzwnRAHo7CkKub1rp2dla0IJ89EVF4aKXna3PrXS7BFn0Qa4bgEIUbXlzwuBj4vKefTaFOLJFH7R8hw76rYZdivK6R32jkZg+6CChX7FCjyFQX0JvE2Yun811w/NWrPD3dGaCGo35egXNZ9dNdbXehzQO2PgIqkiCLHbeX6K0EnUhoJNzy6SkBLjrLvqYN7K06LnDiLS4ZOVQWakFUFreixbZ9ysTHG3YQG8INqGfN49CzQB7tAqLcnExzc/KSmzRy5vWTB3Qvr22yNu3J8HYcUcarQeId90cdVRw/hPGtOgBiuh5993412kW+pNPpoclNze8s4zkxhvpPHzwAeXkKSzU2w+y6IuKwvPvt2mjH1pZwbF/2vNoW6bVzyLoef6HOWov3Vdf9adnltds7Fi6V2wWPVda7dtroec3OCmyQcIVxlNP+X31QUIvfeGmwNWHRc+wKIdZ9J0723vSBgmutNJtsNDLMODcXL09/j74YOC88yjI4803dVbMoHubt5XKuBJRaVUW/aef0vdWW8U/hDYfvcwFImPSZX4YKfSJxl8FglMKACSqnB/HFu/NQs/WWmVlYitAPgSm60c+BNzgxftlX7MUeq4Aw7BZ9PvsQ99BvQfz8+kN6pFHovtve/emPDp8DDxwBP+W8LVOZNErZRd6pbTQ5ebq3zIGm5EVnGyoDuPww4FLL9X/pdBwo3oii96MGJFlSsWi33FHf6NiY7pubMYDX1Ob0JuhxQUFwG676f9BjcqJLHp+RqTQS4teCv7DD+s2F96u2RhvHosT+jQhhd68OYJ89DY2bw5PwgUA++8P/P3v8dN5vajRH0xRkXbdcMPp5s10U4U9yPI4zbcEtv5kgjFpDXFoaL9+VG4ObYuyP/lQcoRMkNCn0ghlpguQx8DfbIFxBZxI6D1Pt1OYwsrHJTsG8bWUFYsUGTNnfVTk+eDOfDahlxY9w9dUHmcqQm+ul0pjbLotelmeMIve7Cy1fr09NUZQBZHIopedD6WPPigJHBMUutoQQt+qXDecce+bb+LnsdBH8atKi94cMOKCC6hR7dhjdcUiqaykbHi2Gy+MrbeOt+j5raCoKLjikDet2QOYRUE+GGzR77EHRYl89ZW2WliAZCNXQYE/7NNm0fMDGtQrNRWhZ6uM9yfLkZUFvPEGjQ0L6Mq4sDCx0N94I+XlNxN/cRlzc7VAsNBLazfR0IypEtYYKyOm+N6Qx5mK60ZuH0iPRf+//6U2sDvfb4mE/uijaXxY2eYD2N8S33xTu0kZ2Rhrw5Yjx2bRM3y/3347pWmwDZoCRIuOqiutyqI3h6mTsOsmzP3Crgsp9Obr+e67U2/M/v3treirV9NreljSJ9uN2alTvNCzuIf1yJNWiwz75G0CfqFgq3vYMPr+7jt9g/ONLF99L7/cvj9p3fC0dFr0jLToeTtZWRRlxLHhF15IHbVOPz3cuu3ena7ZqafGv97L9ASNIfSJLPp//5sa/VkU02HRn3KKfsNJh9DvvDMlpkuWTp3ofpTtQ4ceSu6lCRP09cjMtF87GwcfHB9lxpVHUGOqTeilRR8UNdO1a3DGUCB8LNt00WqEvrY2PKskW/Rhr9vcwUW6bswYbmkd224Y28gzJmPGxE/Lzw+26MOsVFkGs6wsHjaLfvvtdQXAkTAs3vJB4rcCxmbR87R0WPSm4IS5bpg+fejNpFs3v+idcIJ/uWuvDd4vVxpS6Pn8yzLZwlGTjRuX8PkNsugzM+nYx4zR496aZUpV6Lt21cZRFKGvr8bYrCxK6y07XrVvT2/mO++c2JCICot3kGAHWfS2Dn3JwM+FE/o08MsvJHRBWe3mzaOBEqII/aZNwREV0jq23TAc0RJGYSGVV+Ydyc3VNT8LPVsgUX30Jnxj2iz6jAxtfbHQs2DJ5c2bm/dnjsQkt22SjNCvWOF3l/Gx9+gRLPQSfosZN456mDILF5KVGIRsWDM7TMn9mRb9SSfZE8BFhTuM2ZK9tW0b39lJzmNSFXpAH1sqFn1YBsl0ki6h5+cpKP5eVlwyvNOMvkoVJ/QpsG4dddFn+GELi9MeNy5Y6Dt10pYv+3xtFou0jm1CLy36oBuD85zL3BnyITK7tJv+WDnWp1kGTsAl92+z6JWKF/riYmpfePttGiVpypT4twmb+CWy6JPpKFJU5K9ouMLt2VM/oGFCP24cDc94zz3+/SYaU1UmDjv8cOCWW4B7741fzhyXtHPnulm2kyZRefffP37ehRfG965lZAWfqo8eoPvg73+nhGaJMDs2JUrylS7SLfRB94+czhVvZqa+j8xnIWqmVMYJfQqccgo1ynDXevZn23JgDBpE3z16BCc469lTW0bsx5fhiTxakPT72QRMDsH2u9/Z98UPjFw/TOilxbbVVsCdd9Lvu++Ot/auvZbi1gcN0g+iFM5x4+h76FCKm+/Z0x8tcPHF1HN18GDyebMv3yxnfVn0Jmzdb721fuMIE/qcHOq2zufsyiujWZ4nn0zfRx9ND/eECf7z1q0bnTsWeu54Vhe3DUCV8M03249pyJDgtMHyutfFogeA88+3DxxvIu/RoqK6H3tUuIJPVlhNJkyg77ChDLt2pTa2W26h/+3bBws9E6XNAHBRNynBjaTs1w4T+uOOoy7fjz2mU5ma2IR+662133/VKrLA5UW1uU1KSuh1/L33yA1h60TB6wUJvRk+Jm+wdu105x5Jr17UoUspnRucG7fk9kaM0Ot26xY8KAnTvTv14uW3D1tjLJe9PoSeexDLhzNRmJvknnvok4j+/cOFhBu6+e1nv/2oM1eU0cbqm7pY9Knupz4jSEy4QqmrRT92rH8MXxsyco21gp/5IKFPVAHtsAMFPSRz3yZLixP6++8nXzoLTlUVjf/JYmIT+uxs3ei1/fZkFX/0kX+ZrbfWQs/uHfbbAlpgze3a6NnTn5TKxGbRywfHrEDkdmwDLsydq/cpsbluUsHW8MrTcnLqV+i5IpeVbH0+MIlgV9Lw4RRWx+kBkuWnn6JbgoloqPMh78vmKPSpYus4lwwffhi9c12qtDihv+wy+mb/8vr19MAxNqFXSgt9//70kJpCH2TRMzaxChN6INgCsFn00r3Qpg29znNPO/kg29wQQdn0bK6bVLC5aVik8vLq13XzxBPUiD5ggN5nUGNaQ/Dii+RXP/BA4KKLtMsnWWS+/eZCc7foU4Urd/N5vusu8uUHjbPAmEno6oMWJ/QMi6RZUwb532RCLPNVNy+PxDJM6G0ERbzwekHzbRa9KfQ33KD/S2FLJtKhTx+qJMIaqKNgs+j5fF5wQXrDK0123pm6m0sa06LfdVed3vavf228cjQGubn0fK1cqTurNQRcwTe2RW8KfZcu/siuxqTFCj2LqJlozGbRA1rEpduH+fVX/8AE7LpJZAkHWfScjjbo1ZyFO0joTSGTjV7JCH2/flRpReneHoasaGRGx82b6T/3UQh6ENOdnrUxhb41k5lJ2TYzMtLndooCN2IGPdv1TV1dNw1Bi4m6KS0FzjlH/2crcfFi/3I2i97z6PXqn/8Err463qLnAQKysuhjG+7PRtB8OUDzK6/o3xzFw5avTDlgWvSSVC16oO4iDwQPE5eb6x9YIUjo0y3MTugbD+4pWp+DaJgMHUqhvrbcUg1BkOumKdFihN7z9GhKgBZZ06IPSmyVmUkVhRzYGqAMiZK8PO26ycmhkZ2kG0USpYfdEUfo3xwNw0Kfk0Muo//7P3+Dqen/lEJvG+S7IbG5o3ia6bqZNo1SRqTL+msKjbFNiQkTgsMvWxqnn16/4YlhsNAnGlO3MWkxj4SZCyRI6PPy/Pm7w/jDH0jIzfU5h3t2dnxFIAm68EFRLixULIgZGRQxA/jD9My3Ehb6++4DDjgguDwNgc2dxefhqKP80085pX6EyAk9wbHejvqFXTf1OUJUXWkxFr35cD/9NH3LxtjMTHqlNN0bQcME2izNvDw9hmsiN0kUix6gNoDVq8MbleQ6ZrlY6G3d5BuKH3+kbJ1mRkCAKqxFi4Dp0xumLE7oHQ0JW/QN6a5Kllb1SLCvOKofO0jo2e+faDtBF95stOHQKtOil4SFq3FjbGMKvU3gJb17N0w5ACf0joYlUeqEpkAki14pNVIp9b1SaoFS6mrL/N5KqbeVUvOUUrOUUj2N+UVKqWVKqQfNdRsSjqwxBwAYMcL/P6wnm+yclEjog3zPQdN5kPCDD46fl51Nlvt118XPY4u+scLLmhpN+YFztDx4dLBtt23ccoSR8JFQSmUCeAjAIQCWAZitlHrJ8zw5fMdEAFM9z/uXUupAAHcCOFXMvxXA++krdmqwRf+Xv1CHqM8+o9rY7GDDnac4W6VECn26G3+GDQuvZIIGReHONRy22VppCh2mHK2P006LlvStMYli+wwFsMDzvIUAoJR6CsAoAFLoBwDgISjeBfACz1BKDQLQBcBMACJ3YsMjLemZMymftU0UDjwQeO01u2UtB5puKoJyzjnUCeuwwxq7JI2Li7pxOOxEcd30ACBTWy2LTZN8BWB07PcxAAqVUh2VUhkA7gUwPmwHSqlzlFJzlFJz1pgDm6YRaRG3bx+feVEycqRdMDg0s6FybUdBKUqd25CdVJoyTugdDj/piroZD2B/pdRcAPsDWA5gC4ALAMzwPG9Z2Mqe503yPG+w53mDt5K9iZIkSOg4t4w5ZmoqsEWfqtDb3EGO9OKE3uHwE+WRWA5AZnXpGZv2G57nrUDMoldKFQA41vO8UqXU3gD2VUpdAKAAQLZSqtzzvLgG3XSQmWn3Y48cGR7vngws9FEzPm7cqKNsNm1quBzdrRkn9A6HnyiPxGwA/ZRSfUECfyKAk+QCSqlOANZ6nlcL4BoAjwOA53kni2XGAhhcXyIP0ANuE/o2bYC33kpPh4ZkLfp0DenmSIzz0TscdhLal57n1QAYB+B1AN8CeNrzvPlKqVuUUkfHFhsO4Hul1A+ghtfbrRurZx5/3P+/oIAiaC68EDjoID3+Zl3gXp7du0df509/orcKR8Pg3pocDj+RbB/P82YAmGFMu0H8fhbAs+Z6xvJTAExJuoRJMGYM+eGvuIL+d+mS+sAPQXBnqT33jL7OXXeltwwOh8ORDC3O9pGuG+6anE5Wr6bvwY0aKOpwOFJixQry8T3/fGOXpEFxQp8kjzxC2SoHDEj/th3poa6DRDtaMPPn0/eDjdpJv8Fp0UIf1JO0LgwYQMP4uZj1pkdYriCHA4COjti8OX3brKpq8jddixN62UjqrO7What8HQnhTINR8pRHoaaGIjTGh/YJbXRaXCDamWdSNsiCAudHdzgcBuzPTZdFX1FB3//8J3DvvenZZj3Q4iz6jAwaqemQQ6J3anK0DB5+mK77oEGNXRJHk6Wqir7TZdFzxRE18dXnn9OIRvXhVw6hxQm9o/Wy667AG2/Ej/nrcPxGui36ZIX+xBOBZ56JH8y6nnFC73A4Wg9s0adL6Hl7Ubtjc6NtAzfeOqF3OBxNlyOPBCZOTN/22AJPl+uGhT7ZnOUNPEqQE3qHw9F0efVV4Mor07c9FuZ0by9q3g0ODUt3ORLghN7hcLQe0t2LMlmLnl02lZXpLUcCnNA7HI7WQ31Z9MmmTL34YmD//dNblhCc0DscjubH2rXAlCnA2Wcnt54U+mQaRCsrKQXtV1/Zt5esj/7jj4H332+wRtkW12HK4XC0EMJizTt21L8feST6NqXrpqpK5x1PxBdfAK+/DqxfD3zyiX8bQOoDSK9bB3TokNq6SeAseofDkTz/93/Ahg31u4+ofuwtW4LnrV0LTJ+u/0uLPhk/OY9axOs/8wxtmysOm+vmjTeAn34K3246xjeNgBN6h6OlsnIlsGhR3bfz7ruURKqsjP7PmwecdBJw7rl133YYUYU4LFTy4oupkxK7XKRFX1xM5ygK7GKpqgKWLKHerWPGAB98QNNNi762FhgxAhgyJHy7UfdfR5zQOxxNncrK1Dr4dOsG9O1b9/1fcQVZnt9/T/83bqTvdFQiYUQVei6PDa6cvvuOvs3G2BkzEAkuS2WlfpN54w3g1lvpNwv9+vXkclq2jP6vWxe+XSf0DocDALDttv7Bh+vCa69pKzQqLJZmGVJtSHz+eWDOnMTLpUPot96avn/4gb5NoQ+Lwnn9dWDWLPrNycsqK+3rZGbSm0W7dsBVV+n9JbpuznXjcDgAAMuXp29bhx8O7LdfcuuwBbtlC7k+nn6a/kft3Xnrrf4c0qNHB7s0Xn1VC2mQ0JtCy0JfWQk8+ijw2WfAzz8DPXtqHzkPOGLG0YfF1Y8cCRxwAP1moa+qsruKsrKAl1+m3zNnaqFPNLh0A+W8cULvcLQkKipIyH//+/Rtk4W+qopG3bn/fvof1aK/4YbgeZddBjzwAP3+8ENKeXDttfQ/SOjLy/3/WejfeYfCLY84gnzyy5dTtAxALhU+BkmQ0JvHJoWe33AkmZna+h84kPz4AOVLD2KnnSjMcu3a4GXShBN6h6M54XnATTdpi9Fk+XJyzbz4on+dusAiV13tjyJJNl+Lbfn77wcuvZR+84DMvA8p9D/+CNx4Ix2LKfTl5fS2wdN//ZU+gBZR3pYp7EGuGy4Lw+uHCX1JCf3euFEvby4rr8Uuu1BFtNtu9jKkESf0DkdzoaKCGvduvhl44QX7MjYrmIVaEhaSGER1derx4rzPMFcJl4nzxshjOeoo4JZbaHBvUzx/+olcJ3Ic2DVr6Jtj8aVQS2znBgAWLrQvV1UVX9EAtH+uVNav1/sxyyrPO5eNG27rESf0Dkdjcuyx1HgXhdJS7aYIEmqb0NsaK1NxF1RV+YU+2TeFmhp/WUwLXwp9aSmw7756Hq9XWxsvtPx28/77ehoLvSy7/GZs1rnnAQcf7J8WxXXD53TDBn0dzL4G8vpcdBF99+8fv70044Te0XyQllJToaYGOOMMHXqYLP/5D/DnP0dbtrRUNwRu2UKiwb5nxib0tsZD0zURhepqf5bGMNfNG29oXztTU+MXaXM+C31mJvD22/btVlTEC71NeM0G7CDXja3T15o1+pwVFen9hu0vM1OHUm7YoO/Tigr/PuX12W8/auzdaitg6VLqmxAWQVQHnNA7mg/t2gGHHdbYpfCzbBnlXHnjjbptJ0qcvGnRH3wwnRNJVIs+SOgrKihKxubqqK72R8+EdVQaMQK4807/tOpqf1nuvts/n89BZqaOe2fYvbF5c7zQ247l55/9/ysrgUmTgC+/9E83K0qARBcAdtyR9rduHXD99Xp+aWn8OhkZfotenjeuGKqr469zZiZVmBMmUG/jZ56J33YacELvaF688w4NwqxUan7mdMOWXl3TAcybl3gZU+g//JB+SxeKTejLy4Fnn/Vb4EGum3vvpSiZf/yD/kvr1fRPl5eT22T2bD3t7bd1Q6iJadHbygmQaM6da1/GJvSrVsUvZ/Oxn3su8M03/vw2zzwTL9wcMbPjjiTOl1ziF2jb8VVV6XvAJvQffQTk58e3CWRk0LXMy9PL1gNO6B3Nj5tvpu8w0Wgo0iX0bEWGsX69FnqZ8EtapTbX1t//Dhx/PH0zQaGLLDQsbFJ4qqv9x1lWRiGCQ4dS+QcOpLeMI46wbzsZoQ+qLDZt0mVYsQJo08Yu9BwBY/tfWOif9+ST/v8s9DvsQN9mD2DT/w/o8nbrRuf2+ef1vEGDaNR6W0N0ZiYJPYdh1lP+ICf0juaBtFp59O90Wz9z5gB33JHcOjahf/RR6oGaDFF6SJaU+H30zLJllNNl9Wq7gHO4oozuCIo24fPMvnh5XKbQl5frCufss3U+Gel2kdfNbIxlOGGYrMSCfNWbN+uKrX17oHPnaKkY5PbMysY8Z0uWkIXdqxf9N8XXVrGw+MusmkxJCZV79Gg9rWtX+mbXDVfQ6ewcJ3BC72geSGFjoY9q/cyYAXz7beLlhgwBrrsu+TzlZlnOPpt6oEYhP5++o+Q8+eUXe9TNpEnA3/4GXH55eHildN0ECT0vw0Jvum7Mc87W8euv62l8fcx9Bln0bM3yvM2bw4W+tJQqh9xcLcZhmCGhphhv2EBvO+zC+eEHSjvB18Y8Zls4JJ+nTp30tB49/MsMHUrXuaQEWLCAprHrhhty+W0izTihdzQPpEsiWYv+iCOAAQOi7yssD7pJXV03LIRBFr0U9OXLtQByl36AXBgAlZuFXkbHsBvm00/jp61b5/eHcyXHja42i/6AA4DbbqNptrh6KfTSXbFwoe6pKsnJoXK/8oouW5CLZ9MmEmRuhI4i9Bw5A1AvXE5VwEyZAlx4oXY5/e9/1JmJ89SYDbs2i57P+8UXa2vdTCjXvTvQpQvln+dKhF03XMnUkzvSCb2jeSAFo75cN0wyecrrKvRcqaxcSQ2hkyf758sKbvly7bqZOVNPZ+FZu1afk+JiPZ/XkXHm48dTw+mBBwJ77KGnc8XDQm9a9GVlJIJ77UXTbBEosrFTXrdDDomPtAHIz37jjdoFs2lTYos+GaGXPvk99wR23tlfVs43s3w5XcfFi2mZKInkOBqHr1PbthRxBMRHRJkWPkBC//XXVPnst59Oo5BmnNA7mgc2i74uDVf33x+cRiDIrRG2LJcllU5EAAn9+PHAmWf655tCbxNA9uu++SZFiAB+cQsKgzz4YB1uOGMGNSCaPnqb66aw0O+iMJFCH+XtqLYW+Pxz/Z9dNyNHxotjKkIvLfriYv8gIfLto6KCUi0A9AbIVncYQ4YAhx6qz1tWlo6g4bYHxib08s2rHoMLnNA7mgepum5snXoqKymZ1pAhNPqQGalSF4s+mQ5dtbVaIIJcN1GE3nQtAP5kWlEE5IgjqLGQzxeXS1amV15J84uKqJMPM3q0vwFWiqfNVWNSU+NvhCwro2uw9960T8nXX1N7AAv9Ntsk3r6s9IqL/X0BZFk3bdLnqqhIu826dAnedl6eX6wzM4OF3pbJUrq+gkJK04ATekfzIFWLPqyn6IYNNPrQTTf557N4L1mSOFUAL8uRIMn0bGRrNyPD3+lHJg7j8vftS5asGdrXubN921LckrEUWeiDcrUAJILSoi8u9nfjl+JpphKwsXkzVRRHH00JvjhU0RZ3/uij9M3HJ90wjDkGq2nRS0yh5/OdkwNsvz39fuwxir+fMiV+X23b+sVaWvQ5OXRcb71FHerMsE7Avy63e9QDTugdzQMp9OwaiGLR29wwZu9EMyc4P+y9e+tYaht33UXuEoAiKc45xx5jHQQL/dZb+988tttOz+PjZsuVXQsAcNZZVFGZZGT4BSwZuBxXX02duDZsiPdVFxWRtcoCag6wnWjf0qIGqJL0POr1PHiwFvqCgmA3GleMPLCIZPZs4L779H8psCzC06ZROChb3dwoypViTg5Z4J5Hbzs77mjPoR8m9EpRBXjQQdQ+YYPfBjp3jk8JkUac0DuaB7JRz4wImTnT3ztTEkXozR62d9+tp4UJ9zXXAM89p/8/8gjw17/at7thA4VAmnHlAA2QYcI+a2nRA36hz8oC+vWLXzcnhxo4U0FWqHvtpX3yEv7PlrMp7KbLQnLEESTkLIaSbt38lUp+fnBqCG5fMSsNgCpFTn0M+C16Xv6UU4Bdd9UVG7+hcOOyWXkB9jKHuW6i9NzmSsI2uHgacULvaB6YOVcAbdEfdhjFKNuIIvSmH3/qVEoZINlnH794BCX0km4S2Qh66aUUeieTdYUJPUdf8HGz0Mt4+6wse6NoTk642IYhe9lu3kwRPaaPmoWT2wFMUQwTuF69qIL4z3/i53Xt6o9Uyc8HTj/dvp2//U3/XryYXCtBcHltlQJfR25zCBN6WaHxtsIs+ij5+nnduqR/joATekf9k45OIFLo+Te/8ocR1aI3H0rp/6+qAj75RI+EZNuGbbr017M7Qk6TrhsTbpw0LXpJVpbfWmXqYtGbCcJWrtRx4Ywp9KZFH9YgzSJoc++Yg5nn55PLxGxsHj6cUjowvXqFu9jMNxAJV0qm0NsqSllmrpCys/0inaxFz28DTUHolVIjlVLfK6UWKKWutszvrZR6Wyk1Tyk1SynVMzZ9oFLqE6XU/Ni8E9J9AI4mzvz55Ov+7DP7/EcfJRFNhM2iLymJ3lgqsQm92YgqrfGvv47fRlCjq8w+KK17fqBlhcJCYLPouackH3enTvHD0kURepsVG4Yp9N99RwIsMX3z/P3uu/4y22DXjM1i7tLFH0XDx2vGo9tcKGHHyeUNE3p+M+LzHua6addOD9WYnx9s0SfjumlsoVdKZQJ4CMBhAAYAGKOUMrsZTgQw1fO8XQHcAoDzk24CcJrneTsBGAngfqWUcdUcLRpu6Azq4n/22eQWsbFwoW7stFn0JSW6V2gQpqh/8QWw//7+aVu2xDfsSqH/5z/pu08f+/wgpNCzEHkeuW9++klb9IWFOhrkrruA3XePF/rs7HgXSps2dqHPztZCbxNFRh4PY7ZJbNgQb9Gzhcz7YFEcPpxi31Ox6PPzaTvSouf9wtuRAgAAIABJREFUtGtHVj2754KOaexYcruZRLHoowg9T+vUibJ7LlpE25Y++qws7W9vZhb9UAALPM9b6HleFYCnAIwylhkA4J3Y73d5vud5P3ie92Ps9woAqwFsBUfrgR+cZDohMTvuSJ1RgGCLPiwJ1IoV/sbLv/yFMgma1NbaBY6ZNIm+u3ennDk//2x3pZhIq5+FvraWQg533VULfVaWFtOBAylZF7sQZLifKepZWfHhgrxsFKG3HYMta2SQ64b3IUU7Ozt8uEAZeihhS192KpJpK/r0ofNi7k8yeTJw6qnB++b1JUGuG5vQK0X73morOs7evWm66bqxvb0F0YQaY3sAkDlUl8WmSb4CwKnZjgFQqJTyZQ5SSg0FkA3gJ2NdKKXOUUrNUUrNWZNMeJqj6cNCb4tnT/QgsLhv2OAXD2nRs9Dbuqv36EFWHnPFFfb9bNkS30tW5jPJyKAKoqKCxMfspJMR8BjJtwRehre7aZNd6AsKSJDM85adHS/qYa4b9jGHCT0LVSJM1w2LoGnRczlTseh5W5mZwOOP05uXaeWyKyfsmGzwW50ts2QyFj2XeyvDVjVdN3ytm5DrJl3VyHgADyqlxgJ4H8ByAL8dpVKqG4BpAE73PC/u6fY8bxKASQAwePDgOg5Z72hSBFn0771nH93HxooVdot+/XptiUfprh7Eli3xQwFKoe/XjxpMOQ2vSadO9lGO1q+n437gAX2sMjpECj2LaX4+Cf3atZT7RsaL2yx6WyecnBxy/wCUlyZo8GlbI3DQ8TETJui3E65MTKEPi4AJ8tHLxs8zzrCvy9c4WaE/8UTqdXrPPfHzTKEvLSWhDrKwO3aMP2+m64ZFuwm5bqII/XIA8sh6xqb9RswtMxoAlFIFAI71PK809r8IwKsArvM877/pKLSjGWG6IJjhw/3/a2v9D4yMplm+3O6j53lAfGNcMgnPamvJos/N1RWSFO7cXBImczALpnNn//IPPEA5Z9avp7cIOeCHzDpps+hZ6Dn3DUBunq22ihd16Q+WFBUB559PnY/mzw/OjW+zcG1Il8ctt+jftsieRGGdiSz6MIKifBLRrh3wr3/Z55mum3Xrgq15gM6led5M100yQt9UGmMBzAbQTynVVymVDeBEAC/JBZRSnZRSvK1rADwem54N4HlQQ60RmOxokbzzDuU+YTGO6qPn5RjpKzaFvrpaW4Ys9GbyLOmbT8SWLRRZs9tuepq06HNzScCCUi6YOUyOOYa+S0tpHFAJW7tt2wYLvRllsu++9G2KaJDVWVREFd/QoXbXDotalOyMgN23DWhxlm61RILNQm+WPUrcf6oWfdi2zQ5T69aFL9+vX3yjrum62XVX+h3UB8C2bmMLved5NQDGAXgdwLcAnvY8b75S6hal1NGxxYYD+F4p9QOALgBuj03/A4D9AIxVSn0Z+wxM90E4mhB/+xtlQXzsMfof5qOXSGGdPRs46ij932bRszCyW8LcvjlmaBjl5ZSD/He/s5cnUQckMxqme3d6cOXQfwy7miortUBmZemcO926xQvrttvq5SRhQm/7zUybRm9MUd1d7dtTByfOF8/wOZFCbztPjzyif3PlUlxMEUbXXBO8nglXIsn2EQhqQwG01c1WekVFuEVvw7Toe/ak8ztmTPSyNYHGWHieN8PzvO09z9vW87zbY9Nu8DzvpdjvZz3P6xdb5izP8ypj05/wPK+N53kDxefLsH21Kn7+mdLDmtx6K1lkqUSqNDac3Ipzn0e16LkxdNMmskR5kAylSHQ5xBEgNwlbpRy2aW7flic9iM8/J+tahnmaSdTChKhDB50eGKCHvbiYhD6oYXLLFu0KysykhtEbb6TjNXu7cipe0+pLVeh5vaiWcVERvaWYY8Gy4MpjDHIlMXKff/qTjqyJIt7JuESi8tpr1PlKJodLVuhNH30yNBWL3lGP7LKLfSBlzpdSTwMFp5XTTwf++Ef9n607FvggH73JZ5+Ru4W7xmdnk3j27EmDMpgpXFno2fLessXvvkllUBLpupEksugLCym/vaS4OHFlw2U3xcGMcmGhD7LozWESpS+fRXavvbSLidcL6r9gEmQRc+78kSP1NFuFLstjvkWwwEex6FkMo4QtRuWAA4Cnn6ZrbHYAi4rpukll3WQ7tiWJE/rGJJmUtunijjuAV19N3/amTqVwuD/9if6zdcc9Vlnwv/6aKoSggShmz6a0sKeeSg//2rUknu3b2/Ots9UrrUlZmaRSSZoCyySy6FnIPvtMv6EVFyce6JnbIUxxMOPWE1n0Zvd/KaYckpmdHe8m6NJFZ2cE9NvYJ59Eu0cGD6b1t9tOT7OlhpAWvemW4rI0lkUvCcrGmQjTdZMMfE2c0LcCTPGTvSjTzXXXAUceWbdtvPIK8OGH/mn33ENulyChf+01qhDmzIl/UPv39+fD6dtXi1X79vbzYOvlKK1Jm0VvW4cpKCD/sRzq7rLL6DuRRc/RIEOGUII1gBpUzfTHQeVNJPT89hLmo5fDBEqhYvHKztb3lbkdLv/111N7xV57RR/c3MTWY1gKvdnQzGVJxqKPOqZv2PW2karQp8N1U884oW8KBLk16stySYayMhIIOZbpUUfpSBDJokXadbN2LT2QpuBmZMS/yWy1lX+wDfmqbwoDU10dbwVKobdZ9PLBN98SuDHuqquo0jrzTB3GJ1/rmaeeAk6IpW6yDWdXXKzHQA2Cr3uQ8AIU389Ccv75FMPN50Sut+++lA+fy8vk59P1a9MmuOHvuuuo5+mIEXXrjwDY31JlY7WZr4epD9fNjz8mvgYSWSkmg3S/hDX8hq1bz9RvU68jGhUV/geMLa+wruTJ8pe/BMeBm9x0E4nQ0qU64dYddwR3ZGEWLtQWfWlpfMgkQMdmE3pZqUmhDwrtW7eOxFSGYcoKM5FFb+Z5kS4HHr6OR56yWfQdOlBs9qhR9naW4uLomTXDrEAe5Qig6JslS2hUpdLS+PVkugRGKT1QSJDQ77KL3T3Wo4c/DUEUbBa9jDs3XRR8j0dx3YwYQS7CUWYGlgA6dEjOqq+r6yYV0W4g140T+qaA2YDFFz3qK2oUgrr/27j55vhpUd4ufv5ZC73n2UfMufDC+IZLczg8afWx0I8bR75gzglvE3rToudRg5igtwPA3nAqu+WbQr/NNiQIQSF0YfsqKCAXSZBFzwRZlnIgaolN6IHEQh9EUI/aMGxCHyaALPRRrOjddqsfdybD7RkNKfSuMbYVERR6mE6hrytRyiKFHtDje0pmzwbOPdc/zcwdYhP67bf3vwmw0AP6YTF99EFZF23YwiBZ6DMy/Lljli/Xse1B2JKNmeUIE/r16+0JxoBgoWfr33QlnXMOdWJjMalPd8Hjjye3PJ/3VPPnp5O6+uiTddsAzkffqthuO3uulKYu9KZ1tXq1XTDNm9k8VlMUowj91Vfr9XgZFs733ycLfY89KKcOd9sP8g/36QM8+GD8dPkAs9AXFMT3hLUhLXqzy3wUoS8qCq6YgoR+wgTKCS87fgHUyHriiQ3jJth5Z+D22xMvxzQloQ9LZxxGXaxyF3XTyvivJQ0Qi2tZWd1CMdMRxllTQ8nFpJVptiGsWUMPrpkK2Ow5agq92RVfCnL//mRF77abPo5776UGYRZ6FtWKCgpx3H9/6ulaVATst59u/whyD/z8M7mUTFhQpdBHTRsgKy+zYmBBYZFLNlKDy2WKY1ZWfA4hSTLpc+tCMsfDA25H9bvXJ9yAP3hwcuvVReidRd/KsI1HyUJfVJQ40+DHH/tHN5LY3haSZc0aapyTbhYzZvrXX0m8ioooeoUJik9nzEgPeS4OPpgakbt21ULPy7OA8vcrr/gH+2BBTSZWW8KCKIU+alSKFHqzcuD/nAcn1e7vya4nc+LXJ0Hn2TaQ+cCBVEEffXT8vIaGe2cHdZwLoi5WubPoWxm2jHzSXWKLYJEMGwb84Q/2eWFCX1lJN5nMsBgVs22BLfrsbL+4mT54SXZ2vHjKm14p3W1+/HjqHDQ6NvQB+6T79CELf9o0v8jwflnYTGG84ALghhuCyyaFnv22UYVeum74OnKFZLrBUrXok12PO1YlmxQsWeQ1mDaNvhcvpj4UNpL1idcX991Hb0RBA80HURer3DXGtgLkxbXdLFF99CeeGD7fJvRVVZRJkV1GcuDrqJgWvRR6KSY2n+fJJ9N3Tk508ezfn7r7s4Czhbh0Kf3evNlfJu7pGRTC99BD9ggjJl0WPbsEuLxmBdlQQv+vf9FbjzlwSrrh83zuucApp9DvXr3seXeaEsOGURtHqlE3znXTyqiqSi4XNeAX9WTi6CsqgOnTw5exdR46/nhgp510RkIeqCJRThqJKfQVFdQI2qaN36K3iSO7onJzo/u9TXgovFWraBubNvnffNji53Pbpg25tz76KNr2pdAzqfjoedARFti6Cn2q6xUW2mP+0w2XK539QJoyznXTSsnJAY47LvFyUujlQxE1jn716miv4bb8Iy/FhhT4+mv/9GQGdbCFhS5fHm/R9zBHnoQOAbRZ9FFv+v79aXDxqVNJgGtr/W83LPTSoj/uuOjJvKTQm+0DiZCuGxZ6rpjM69FQFn1DwccpO3u1ZJxF34p54YXEy8iLfMgh8fm+L75YD2Jg47vvopXFJvQMi9D69YktMJkHBqDXXIZ93TYfvS1FAFv0Nh+9maY3iIwMGrh70KB4S7t9e21VJ9P7UiKFnjsCJeu62W47/ZY0ahRFFJkdyVqa0B94IPDBB3qErJYOu3pSCYd2PvpWgFmby2HaAPJH/+9/wetz4jBJTQ0JuwyDjCr0icZwHTTI72fl3rbvvefPxy6FPjPTLvQccinzyPToATz8MPWCTRZT6OW4pakKvUy4xSF3xx8fbd2cHEp/KyvD/v0pVPagg/zLJptbpakLPUCx/A1krTY6XKmnEsbsXDfNlKDQtcWLaUQd2cnIfBDYagy66KtXk+XM/n9bI2tlJb0dhIVBSrjr//r1ifOnd+9u7/2Xl0cNrpyuVrpuMjPjQ0MnTtTHmJOjK49Ro4Dzzkut84wp9NIFlarQX3YZvVVdcgnlg6mpSS6r4/HHU66gYcPoP1do8ro/9VTqnYWastC3JsLSXSTCuW6aKUEjCh11FA2btnSpnmZe5DBBBsjSvfVWGpcVoA5MJpWVurGRXQabNweLCVvx33xDPSvD6NbNXgmxqO68M31Liz4rK17or7jCn5elUyfKXmnmwEkGs63C1kbACdqiUlBA0Ujsrkn1oXz99eDrnqw1D/g7cjkaHyf0LZgtWyiz37PGmOdBUSvsZlGKLMyvvopfJpHQs8VdVUUuHVtvWtlAOm8eiexHHwU32srXzaeeCt7322/TDR0mLvwW0aaN36LPy/O7MAAd+siZIrfZpm7d4E2LXgroJZdQm0lQP4P6Jj/fX8nUZUQiQAt9Pb/uOyJSF6F3rpsmSnk5PWibNpEPnUd637SJxD9I6Nml43mU/3vgwPi0wYmEnm+GFSvIHfD66/HLSKGfMoUyEH74YfKdZG6/nVIbMwce6C8DQFkn775bW/LciCrDK1nUzK75nTrRuTj22OTKFYQp9GYfhVGjmo4w1lXoHU2LsAR2iXAWfRNk3TqKRb7tNr9wA2S1nXlm8NB2vHx1NaUrsJHIR8889hg16k2dGj9P7lPmGE9W6HfbTacElkiLvmtXSnXA5eXkXZs2+S165h//0D0l002qsfiNQV2GngOcRd/UqIvQ8zV0Fn0TYs0a+n70Ud3A53n6wZs61S+0N99MFUNtrW5Ara72P9xjx+rfXEkEXXTe9qefkpvkpJPil5VvBXJ0HVPoZWNtz57xaXdzcuzlkNNMa5Rv+PXrtetEHqvsKZlumqvQp2LR86ApTSV1QGsnHdfBCX0TghNmVVX5B9iQvWCl0N95px5gQgq9tIrNuOwRI4CVK+3754oGoBC9zMz4G0S6g2SIZV6ef19yhKWDDgIWLPBvJ8hfHjY+JkfPbNig/ZY87mp905qE/rnnKHQzSrpkhwNO6JNDNoZKi152NLJF3VRVaddNVZX/QTct7TfeCO649Msv+veIEfRtCv3y5fq3TAeQl0dvAjyaE/deBLRFsvfeelpQ54+oFn3btnRurr7avp1001yFPhXXTceO0eP5HU2b+hwxS+CEPhlY6Csr/WIsf9saY02LXj7cyQjUunWUWe+ii7QLxBR62YAqxTovj3Lb3HYb/Zeizm6Wt97SPXGDwkTDLHoOo5SVSEPRXIXeNca2DK65JrXEgA3U3tK677Jvv6Uej998A/TunXh5jjmXQm9a9Dahl0nOJk4kq50xLfrddwfmzrXvv3t3ssol5g0S1JOW93PmmbSd4cO1W4Ut+rZtgT//md4WOMnZTz/5/f5S6E1rdMAAqixkJdJQ1Hfq3XTihL7lcccdqa3XQELfui36SZMoQuS556ItzxZ9TU1yQi8tenNfUqAWLdICayMZUTCHr+NOTZmZlMFQ7lc2Jh16KB0Tj7e6zTb0JsCEWfQA+fsbw7rOzKQ0vED8WLFNjbq6bhyOJGndQp9sD0OZIoAbZpP10ZtIkTWzPprYhDXIEjB7gZrbzcjQIpNM1ECYj76xOe006keweHFjlyScpnwOHY2Ds+jrEbayUxF6zvGerEVvIqNbGlLoAX3cyQh9mOumKZCTk1pagcbCCX3rxjXGNgC2gSXCkNkdy8r0NhIJ/erVwRdUrmsO2GGSjNCbOeBt6XVlYrGoOGs0vTTFytLRcDgffQOQrNDLGHUWeiCx64ZDISXcUYoHJAbSa9G3b+//bxu3NRWhT+SjdySHO4cOwAl9vTBnDuV/SVboly3Tv4OEPspQfFdfTZkaR42iUElGJgOzYevENHOm/n3GGfp3YaF/OdtgHqn46PfYQ/92IlV33Dls3TjXTR248kpg333t8+bPB4YMofnJCv2SJZSqF/ALvRS/H39MvB0e/eiFF/wx55zpMQibKOy3n+6UxPnggfhOVzaLnqNTkhH6xx6j4fuCyuNIDncOWzfsUo06qlqKtEyhnziRLHYbnGkRsAt9ba0/dQBTXk6phnkcTCn05r4TYbpVJMn66AH7a99uu/n/24Se+w4kI/Rt2+o4eedfrjvuHLZuDjkEePDBuo3FEIGWKfRBmN36OVukFPo77yRRlG4aQA8c0a8ffXN4ZSqECX2yFr1EvgYecwyVkSsBm9BzvhuZKiEKfB6dNVp33Dls3SgFXHghDXJTj7QuoTfHRGUxlzHuL73kn8eYQh9k0UchLK2pKfQjRwKnnkq/g0SBI2y6dCG3Cqc5yM/X4m97NRwyhL6TbQgaNYoqCR4z1pE6TugdDUDrustMy5XFW1r6/Cptxr1z3Dz76OuSV10OsG1iCv1rrwEvv0z7C8ooed55JOTHHw+cdZZ/XmYmHYttFJxzz6W3i+OOS678nTv7c907Use5bhwNQOsQeu7UVBeh5yH3OnRIrQwsuEC40Et/ObtW2CoPsv4yM4ETTrDP++ILyo9js9ozMoATTwwttqOecRa9owFoHa6bRx8lATUTfslRnxh+8EyhZ39+FKG3Pbw336x/m6GPEu7Vue22FCEE1M0nvuuuOkrG0fRwQu9oACIJvVJqpFLqe6XUAqVUXIJxpVRvpdTbSql5SqlZSqmeYt7pSqkfY5/T01n4yPCg17bBtIFoFn0yQs853yWysSXMomf3TNu2OgKHKyInCi2PqKG9DkcdSHiXKaUyATwE4DAAAwCMUUoNMBabCGCq53m7ArgFwJ2xdTsAuBHAngCGArhRKRUSclJPsEDawiYBu9DLabNmAePH0+8oQm9LeSyFPqyFnYVe9rDlsgT56B3NFzfuq6MBiGJODAWwwPO8hZ7nVQF4CsAoY5kBAN6J/X5XzB8B4E3P89Z6nrcOwJsARta92EnC4i1HX5JUV1OP1uuvp+yHgL+H6wEH0LdS9pwxkm7dgMcfj58u1wuz4jgMkvcJuHBGh8NRJ6IoRw8AS8X/ZSALXfIVgNEAHgBwDIBCpVTHgHWNbFuAUuocAOcAQK9evaKWPTos9J99Zp9fU0O56W+/XU+zpTLwvMSdiyZNSmzRm0yYoF1DW21F47fyaE0AcNRR1NHr2mvD9+1wOBwW0mUijgfwoFJqLID3ASwHEJCXNx7P8yYBmAQAgwcPTl/yB88jKzyRJVxTEx8Xz5a9SaJwuMGD7cuEvQnccov//7bb+v936BA8cpTD4XAkIIrrZjkAYV6iZ2zab3iet8LzvNGe5+0O4LrYtNIo69YrHFUjhd72xlBTE9/4WllJAhyUSsFGaSnlj7FVLDwWq8PhcDQwUYR+NoB+Sqm+SqlsACcCeEkuoJTqpJTibV0DgJ3UrwM4VCnVPtYIe2hsWsPA4i0tbHOIPYB89GZ6hIoK4MYbg5Oj2eDGUpsP3rZfh8PhaAASCr3neTUAxoEE+lsAT3ueN18pdYtS6ujYYsMBfK+U+gFAFwC3x9ZdC+BWUGUxG8AtsWkNg20EKRZc2VO0pkb3fGWSzf8C2KNi3n8fWLUq+W05HA5Hmojko/c8bwaAGca0G8TvZwE8G7Du49AWfsPCVrpsWD3vPOCtt2gQax6ou6YmPg/OmjX696BBwOefJ96fzWWz8846idl774UnNHM4HI56oOX11pAZHNmi37xZTzv2WPLdH3WUnlZd7R89CqDh/5jBg4P3IbHFREvx328/YJddgsvucDgc9UDLE3qZzoCF3oygUYoseqamJl7on35a/5Y57E2uuSa8PC723eFwNDItT+hlj1KbRc/07EkfgPK2f/tt8DZtvWEXL6aEYXfcEV4eJ/QOh6ORaXkqZEsdwEJv+seXLgV22IHSAFdVUUOtadkDNFTg008D/fvrab162UM1TVwaWofD0ci0bKGXrptRo3RyM0mbNrROTg5w9NHA5Mn++Z9/TpXBDjsE7/PNN4N73bqkVY46UF1djWXLlqEiqAOfo9WRm5uLnj17ok0Sua9antDbfPSbN1M4ZW5u/PLsWhkwwJ4+OIrVfvDB9HE4orJypT3NhsGyZctQWFiIPn36QLkEaK0ez/NQUlKCZcuWoW/fvpHXa3lCLy36yy+nDk8VFcFjsbLQ77yzfZmwlMIOR6p06RJpsYqKCifyjt9QSqFjx45YI8O/I9Cyhf755+lTWBgs9Oy/32kne34bHgjE4WgknMg7JKncDy1b6JnNm4OFnuPlt95aDwg+YADwpz8Bc+bUTxkdDoejAWl5LYU2oa+pCR6+jwcj6dpVVwaFhcBppwF//Wv9lNHhaCaUlJRg4MCBGDhwILp27YoePXr89r/K9qwJ5syZg4svvjjhPvbZZ590FdcRQOuw6AGguNg+nXu5dusGLFxIv80EZw5HK6Vjx4748ssvAQA33XQTCgoKMJ5HWwNQU1ODrIC+IoMHD8Zgs1e5hY8//jg9hW1AtmzZgsxmFDrd8oQ+KAwtSOgZadHLyB2Ho6lw6aVATHTTxsCBwP33J7XK2LFjkZubi7lz52LYsGE48cQTcckll6CiogJ5eXmYPHky+vfvj1mzZmHixIl45ZVXcNNNN2HJkiVYuHAhlixZgksvvfQ3a7+goADl5eWYNWsWbrrpJnTq1Alff/01Bg0ahCeeeAJKKcyYMQOXX3458vPzMWzYMCxcuBCvvPKKr1yLFi3Cqaeeio0bNwIAHnzwwd/eFu6++2488cQTyMjIwGGHHYa77roLCxYswHnnnYc1a9YgMzMTzzzzDJYuXfpbmQFg3LhxGDx4MMaOHYs+ffrghBNOwJtvvomrrroKZWVlmDRpEqqqqrDddtth2rRpaNu2LVatWoXzzjsPC2OG48MPP4yZM2eiQ4cOuPTSSwEA1113HTp37oxLLrkk9WuXBC1P6GWOGkkioW/XTgu9s+gdjlCWLVuGjz/+GJmZmdiwYQM++OADZGVl4a233sK1116L5zhhoOC7777Du+++i7KyMvTv3x/nn39+XCz43LlzMX/+fHTv3h3Dhg3DRx99hMGDB+Pcc8/F+++/j759+2LMmDHWMnXu3BlvvvkmcnNz8eOPP2LMmDGYM2cOXnvtNbz44ov49NNP0bZtW6xdSwl0Tz75ZFx99dU45phjUFFRgdraWixdutS6baZjx4744osvAJBb6+yzzwYAXH/99Xjsscdw0UUX4eKLL8b++++P559/Hlu2bEF5eTm6d++O0aNH49JLL0VtbS2eeuopfBbU96YeaHlCv3KlfXoioVfKWfSOpk2Slnd9cvzxx//muli/fj1OP/10/Pjjj1BKoTrg+TniiCOQk5ODnJwcdO7cGatWrUJPTkMSY+jQob9NGzhwIBYtWoSCggJss802v8WNjxkzBpMmTYrbfnV1NcaNG4cvv/wSmZmZ+OGHHwAAb731Fs444wy0bdsWANChQweUlZVh+fLlOOaYYwBQJ6QonHDCCb/9/vrrr3H99dejtLQU5eXlGDFiBADgnXfewdSpUwEAmZmZKC4uRnFxMTp27Ii5c+di1apV2H333dGxAceoaHlC/8sv9ulB8fDvvafXcRa9wxGJfDE05oQJE3DAAQfg+eefx6JFizB8+HDrOjlivOXMzEzUWJ6zKMsEcd9996FLly746quvUFtbG1m8JVlZWajlkemAuB7J8rjHjh2LF154AbvtthumTJmCWbNmhW77rLPOwpQpU7By5UqceeaZSZetLrS8qJtkLfr99gO4lnYWvcORNOvXr0ePHj0AAFOmTEn79vv374+FCxdi0aJFAIDp06cHlqNbt27IyMjAtGnTsCXWM/6QQw7B5MmTsWnTJgDA2rVrUVhYiJ49e+KFF14AAFRWVmLTpk3o3bs3vvnmG1RWVqK0tBRvv/12YLnKysrQrVs3VFdX48knn/xt+kEHHYSHH34YADXaro+NdXHMMcdg5syZmD179m/Wf0PR8oQ+yKKIYelvAAAKyklEQVRP5LoBnEXvcKTAVVddhWuuuQa77757UhZ4VPL+v737j42iTAM4/n1AsB4QfqppruTKSSulLttuW1B+KFXuUggp4YeVgjmamqgVE20uIoQEPA0xBKKAwctBOM+YyxXxOA4Vwwmi0TTRQu0WbKm2sZcDoSDyyyDGHu/9sW/3lrYrbdky3XefT7LpzDuz0/fZTp9O35l55pZbePXVVykoKCAnJ4chQ4YwtJPf5yeeeILXX38dv9/P0aNHw0ffBQUFFBYWkpubS1ZWFuvXrwfgjTfeYNOmTUyYMIHJkydz8uRJRo8eTVFREXfddRdFRUVkZ2dH7dcLL7zApEmTmDJlCuMiamFt3LiRAwcO4PP5yMnJoa6uDoCBAweSn59PUVHRDb9iR0y0h2h4JDc31xzs6Y1Kly9DRkboa/sj+9bWa1eS/PLLUIXKkSP/f319T6WnQ3Nz9Ms9leqC+vp6MjIyvO6G577//nsGDx6MMYalS5eSlpZGeXm5193qlitXrhAIBNixYwdpaWnXta3O9gsROWSM6fR6VreO6F95JZRcFy3quKwrf0FjOXRTX995HXylVLdt3bqVrKwsMjMzOX/+PI899pjXXeqWuro6xo4dywMPPHDdSb4n3DoZ+8knoSPyxYvhpZe6//5YDt3E0c0USvV15eXlcXcEH2n8+PHh6+q94M4RvTGhmvATJ3ZMsrfe2rVt6MlYpZSD3En0x4+HxuXz8jo+vq+7iX7x4tj2TSmlPOTO0E1yMtTWwm23wdmzVy/raqLv1w+++y56ATSllIpD7iT6/v3B5wtNX7hw9bJRo7q+nfbPlVVKqTjnztBNpPZDNyUlnnRDqXiXn5/P3r17r2rbsGEDZWVlUd8zffp02i6RnjVrFufOneuwznPPPRe+nj2aXbt2ha9BB1i1ahX79u3rTveV5WaijzwZ+9NPMHu2d31RKo4VFxdTUVFxVVtFRUXUwmLt7dmzh2HDhvXoe7dP9M8//zwz4uzZzG1353rN/UQfpVa2UvHm6adh+vTYvmzV3KgWLFjAu+++G37ISHNzM9988w3Tpk2jrKyM3NxcMjMzWb16dafvT01N5Vt78+GaNWtIT09n6tSpNDQ0hNfZunUreXl5+P1+5s+fz6VLl6isrGT37t0888wzZGVl0dTURElJCW+99RYA+/fvJzs7G5/PR2lpKT/aB62npqayevVqAoEAPp+Po0ePduhTc3Mz06ZNIxAIEAgErqqHv3btWnw+H36/n+XLlwPQ2NjIjBkz8Pv9BAIBmpqa+PDDD5kdcQD55JNPhss/pKam8uyzz4ZvjuosPoCWlhbmzp2L3+/H7/dTWVnJqlWr2BBRvG7lypVs3Ljx539IXeBmotfkrlRMjBgxgokTJ/Lee+8BoaP5oqIiRIQ1a9Zw8OBBamtr+eijj6itrY26nUOHDlFRUUFNTQ179uyhqqoqvGzevHlUVVURDAbJyMhg27ZtTJ48mcLCQtatW0dNTQ133HFHeP3Lly9TUlLC9u3bOXz4MK2treHaMgCjRo2iurqasrKyToeH2soZV1dXs3379nBd/MhyxsFgkGXLlgGhcsZLly4lGAxSWVlJcnLyNT+3tnLGCxcu7DQ+IFzOOBgMUl1dTWZmJqWlpeHKl23ljB9++OFrfr9rcTMj6s1KykFeVSluG76ZM2cOFRUV4UT15ptvsmXLFlpbWzlx4gR1dXVMmDCh0218/PHHzJ07N1wquLCwMLwsWrnfaBoaGhgzZgzp6ekALFmyhM2bN4cf6jFv3jwAcnJy2LlzZ4f3J2I5Y030SqmfNWfOHMrLy6murubSpUvk5OTw9ddfs379eqqqqhg+fDglJSUdSvp2VXfL/V5LW6njaGWOE7GcsZtDN5rolYqZwYMHk5+fT2lpafgk7IULFxg0aBBDhw6lpaUlPLQTzb333suuXbv44YcfuHjxIm+//XZ4WbRyv0OGDOHixYsdtnXnnXfS3NxMY2MjEKpCed9993U5nkQsZ+xmou9nw+rO9fNKqaiKi4sJBoPhRO/3+8nOzmbcuHEsWrSIKVOm/Oz7A4EADz30EH6/n5kzZ5KXlxdeFq3c78KFC1m3bh3Z2dk0NTWF25OSknjttdd48MEH8fl89OvXj8cff7zLsSRiOWO3yhRHevFFmD8/VC5YqTilZYoTT1fKGSd2meJIK1ZokldKxZXeKmfs5slYpZSKQ71VztjdI3qlHNHXhleVt3qyP2iiV6oPS0pK4syZM5rsFRBK8mfOnOn2JaE6dKNUH5aSksKxY8c4ffq0111RfURSUhIpKSndeo8meqX6sAEDBjBmzBivu6HinA7dKKWU4zTRK6WU4zTRK6WU4/rcnbEichr493VsYhTwbYy6Ey805sSgMSeGnsb8K2NMpw/I7nOJ/nqJyMFotwG7SmNODBpzYuiNmHXoRimlHKeJXimlHOdiot/idQc8oDEnBo05McQ8ZufG6JVSSl3NxSN6pZRSETTRK6WU45xJ9CJSICINItIoIsu97k+siMifReSUiByJaBshIu+LyFf263DbLiKyyX4GtSIS8K7nPScio0XkgIjUicgXIvKUbXc2bhFJEpHPRCRoY/6DbR8jIp/a2LaLyEDbfrOdb7TLU73s//UQkf4i8rmIvGPnnY5ZRJpF5LCI1IjIQdvWq/u2E4leRPoDm4GZwHigWETGe9urmPkLUNCubTmw3xiTBuy38xCKP82+HgX+eIP6GGutwO+NMeOBu4Gl9ufpctw/AvcbY/xAFlAgIncDa4GXjTFjgbPAI3b9R4Cztv1lu168egqoj5hPhJjzjTFZEdfL9+6+bYyJ+xdwD7A3Yn4FsMLrfsUwvlTgSMR8A5Bsp5OBBjv9J6C4s/Xi+QX8E/hNosQN/AKoBiYRukPyJtse3s+BvcA9dvomu5543fcexJpiE9v9wDuAJEDMzcCodm29um87cUQP/BL4T8T8MdvmqtuNMSfs9Engdjvt3Odg/z3PBj7F8bjtEEYNcAp4H2gCzhljWu0qkXGFY7bLzwMjb2yPY2IDsAy4YudH4n7MBviXiBwSkUdtW6/u21qPPs4ZY4yIOHmNrIgMBv4OPG2MuSAi4WUuxm2M+S+QJSLDgH8A4zzuUq8SkdnAKWPMIRGZ7nV/bqCpxpjjInIb8L6IHI1c2Bv7titH9MeB0RHzKbbNVS0ikgxgv56y7c58DiIygFCS/6sxZqdtdj5uAGPMOeAAoWGLYSLSdkAWGVc4Zrt8KHDmBnf1ek0BCkWkGaggNHyzEbdjxhhz3H49RegP+kR6ed92JdFXAWn2bP1AYCGw2+M+9abdwBI7vYTQGHZb++/smfq7gfMR/w7GDQkdum8D6o0xL0UscjZuEbnVHskjIrcQOidRTyjhL7CrtY+57bNYAHxg7CBuvDDGrDDGpBhjUgn9zn5gjFmMwzGLyCARGdI2DfwWOEJv79ten5iI4QmOWcCXhMY1V3rdnxjG9TfgBPATofG5RwiNS+4HvgL2ASPsukLo6qMm4DCQ63X/exjzVELjmLVAjX3NcjluYALwuY35CLDKtv8a+AxoBHYAN9v2JDvfaJf/2usYrjP+6cA7rsdsYwva1xdtuaq3920tgaCUUo5zZehGKaVUFJrolVLKcZrolVLKcZrolVLKcZrolVLKcZrolVLKcZrolVLKcf8D8ho8fZTnddMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code below to save the model as `savedmodel` format.\n"
      ],
      "metadata": {
        "id": "RB-KdKtOZ7zq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVjphkIsbA7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368ad022-a0a7-4585-cdef-da6d371effde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/savedmodel/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, '/content/savedmodel')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code below to save the model as hdf5 file."
      ],
      "metadata": {
        "id": "5G0YpMnIaKwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yqBU5urw3q5"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Capstone Project/binary_model_ori_v5_64.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test the inference from the model, run this code below."
      ],
      "metadata": {
        "id": "sx2zlDhAaUxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwCU2JCXg1pL",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fcdd5db-1d8d-47ac-dfb6-cdd185318851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-072e0216-585d-44bc-8fcd-8fb1861728f4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-072e0216-585d-44bc-8fcd-8fb1861728f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test1.jpg to test1.jpg\n",
            "Saving test2.jpg to test2.jpg\n",
            "Saving test3.jpg to test3.jpg\n",
            "Saving test4.jpg to test4.jpg\n",
            "Saving test5.jpg to test5.jpg\n",
            "Saving test6.jpg to test6.jpg\n",
            "Saving test7.jpg to test7.jpg\n",
            "Saving test8.jpg to test8.jpg\n",
            "test1.jpg\n",
            "[[5.10595077e-09 8.48156589e-16 8.14504934e-15 6.35383088e-08\n",
            "  1.15960725e-14 4.98222748e-11 4.16716887e-07 6.04319309e-16\n",
            "  3.60677838e-02 1.90663112e-08 2.60003219e-09 9.63807881e-01\n",
            "  1.84177570e-17 6.92445834e-09 1.83548185e-12 6.52090036e-13\n",
            "  4.02127593e-12 1.49023350e-07 3.40557786e-18 9.86019556e-18\n",
            "  8.10393040e-13 1.14803787e-18 3.34329867e-13 7.16544662e-12\n",
            "  2.03264321e-08 3.63844947e-07 2.15227427e-08 1.23314981e-04\n",
            "  4.40318232e-17 1.20366315e-15 1.57377854e-12 5.07821578e-15\n",
            "  5.26839718e-11 8.98335077e-20 3.58313598e-17 7.22026022e-18]]\n",
            "96.38078808784485\n",
            "B\n",
            "test2.jpg\n",
            "[[4.2218208e-12 9.9991727e-01 1.3063388e-15 6.0996429e-12 4.8335321e-16\n",
            "  2.5063665e-11 7.9654308e-18 5.4847847e-06 2.0551075e-27 3.3135397e-14\n",
            "  8.9081093e-10 1.7967198e-13 1.4970077e-19 4.2882266e-14 2.5939620e-24\n",
            "  2.9006598e-16 6.9399653e-27 8.4415314e-13 1.5747675e-13 1.9040523e-07\n",
            "  8.2551540e-14 7.9753853e-15 4.0863894e-13 4.5491895e-11 7.3015517e-17\n",
            "  4.2775469e-19 5.1496101e-15 4.3564557e-21 3.3243053e-15 7.6786971e-05\n",
            "  1.2468210e-12 1.7363000e-07 2.3594066e-13 2.6551306e-10 1.5238025e-07\n",
            "  1.6033357e-13]]\n",
            "99.99172687530518\n",
            "1\n",
            "test3.jpg\n",
            "[[2.5833485e-20 2.1326099e-16 1.2296926e-15 2.4165984e-14 3.9523371e-20\n",
            "  1.0000000e+00 9.0791874e-10 1.1266050e-16 2.7201967e-18 1.3220267e-10\n",
            "  1.1088203e-18 9.9695242e-17 2.5183101e-22 5.2407490e-21 5.9842913e-13\n",
            "  1.1757277e-13 1.8964261e-18 7.6829143e-20 2.7633969e-22 4.2004635e-17\n",
            "  8.3466579e-21 8.4750016e-27 7.9444704e-21 2.0907878e-23 1.3680019e-14\n",
            "  4.2898044e-16 3.4667146e-20 4.1619104e-18 1.9735156e-09 1.4835294e-16\n",
            "  1.2924635e-22 1.0954647e-23 2.6576646e-22 6.7205620e-20 1.6763407e-22\n",
            "  1.1741812e-17]]\n",
            "100.0\n",
            "5\n",
            "test4.jpg\n",
            "[[2.42119281e-18 5.87930704e-10 4.56003235e-08 9.43339265e-13\n",
            "  8.54771017e-16 5.76264432e-14 1.23273822e-26 9.99999762e-01\n",
            "  1.97200087e-33 2.29638925e-20 1.28433232e-17 2.49497092e-20\n",
            "  1.13040008e-19 1.25725779e-19 7.68291511e-27 4.43206668e-20\n",
            "  4.93501386e-22 2.38494653e-26 2.71359837e-15 4.32919175e-16\n",
            "  3.65373787e-20 5.74516205e-25 5.73475150e-21 2.13082768e-17\n",
            "  4.97800270e-17 5.37517420e-19 6.23059067e-23 1.03251624e-20\n",
            "  6.82541893e-23 1.35987011e-09 4.16246138e-20 6.73365782e-17\n",
            "  3.84601172e-25 3.90858060e-15 1.56255027e-15 1.33134165e-07]]\n",
            "99.99997615814209\n",
            "7\n",
            "test5.jpg\n",
            "[[2.6212680e-12 9.9996495e-01 4.8741995e-17 1.4663370e-12 2.2405959e-17\n",
            "  1.1311389e-12 6.2522907e-19 6.4347989e-07 2.2093833e-28 7.0985033e-15\n",
            "  6.1078331e-10 8.9724465e-14 2.2593881e-21 2.0830221e-14 2.7994960e-26\n",
            "  1.5063609e-17 1.2587344e-28 1.7175349e-13 1.6384448e-14 4.1861313e-08\n",
            "  1.4866903e-15 3.8720250e-16 2.0779716e-13 5.9190770e-11 2.3270356e-17\n",
            "  3.5851446e-20 4.9533424e-15 7.1895814e-22 2.1627963e-18 3.3758326e-05\n",
            "  2.6715598e-13 6.1191184e-07 1.4093606e-13 2.4545099e-12 1.7992070e-08\n",
            "  7.4607949e-15]]\n",
            "99.9964952468872\n",
            "1\n",
            "test6.jpg\n",
            "[[1.6479011e-05 6.3274507e-05 1.2470220e-13 3.2215322e-09 7.5190826e-10\n",
            "  2.6586940e-12 5.7276839e-10 8.6198037e-07 4.6037410e-12 2.4177373e-08\n",
            "  4.3943123e-06 1.3751478e-06 3.0414795e-14 6.1706004e-08 1.3008524e-16\n",
            "  7.1145262e-10 5.1813616e-19 2.3839033e-07 1.8247120e-15 1.5389678e-06\n",
            "  5.4330285e-10 3.9709422e-13 6.6856694e-07 3.4040904e-03 6.5145068e-12\n",
            "  6.0581260e-14 6.1427581e-06 4.4260092e-11 7.5607185e-13 2.5881136e-06\n",
            "  6.4162538e-07 9.9606031e-01 4.1831331e-04 1.8943188e-08 1.8897621e-05\n",
            "  1.6669168e-15]]\n",
            "99.6060311794281\n",
            "V\n",
            "test7.jpg\n",
            "[[1.8295531e-17 5.6703516e-14 4.4898236e-20 9.4620150e-20 4.0175262e-24\n",
            "  1.1504982e-13 7.5696970e-11 1.5910775e-14 2.0598612e-20 3.7148203e-19\n",
            "  1.4672314e-15 7.2491709e-14 2.1207683e-10 3.6118305e-14 1.6937373e-04\n",
            "  9.9982470e-01 1.7291781e-14 6.7105799e-10 2.1574539e-11 6.8658419e-17\n",
            "  2.3342448e-12 3.3696797e-14 1.7025368e-16 9.0434505e-17 6.7302377e-19\n",
            "  5.9046183e-06 2.2474513e-20 2.3093649e-09 2.8749945e-20 4.2627761e-08\n",
            "  1.5204746e-21 1.4042761e-18 1.6723403e-17 2.2669205e-19 1.8609767e-15\n",
            "  2.5149280e-17]]\n",
            "99.98247027397156\n",
            "F\n",
            "test8.jpg\n",
            "[[4.21277981e-08 6.99358165e-01 2.01328565e-10 1.89588034e-09\n",
            "  1.12139010e-13 2.35633456e-06 1.03798150e-16 3.16282931e-05\n",
            "  8.86032870e-24 1.68005228e-11 6.56030608e-09 1.04942766e-09\n",
            "  6.27435126e-09 1.79246896e-07 1.25689356e-14 1.13410191e-10\n",
            "  3.89816489e-14 2.70103651e-09 1.98251619e-05 1.11060690e-05\n",
            "  5.09269502e-11 2.14819096e-07 3.22512328e-17 2.92114228e-12\n",
            "  8.03576091e-15 1.45558610e-09 1.66846693e-11 6.82704964e-14\n",
            "  1.68021347e-10 3.00573707e-01 2.00013561e-09 1.54747708e-11\n",
            "  1.39471903e-14 6.31814254e-11 1.50999119e-06 1.21206290e-06]]\n",
            "69.93581652641296\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "dictionary = {0:'0', 1:'1', 2 :'2', 3:'3', 4:'4', 5:'5', 6:'6', 7:'7', 8:'8', 9:'9', 10:'A',\n",
        "    11:'B', 12:'C', 13:'D', 14:'E', 15:'F', 16:'G', 17:'H', 18:'I', 19:'J', 20:'K',\n",
        "    21:'L', 22:'M', 23:'N', 24:'O', 25:'P', 26:'Q', 27:'R', 28:'S', 29:'T',\n",
        "    30:'U', 31:'V', 32:'W', 33:'X', 34:'Y', 35:'Z'} # the inference result are in one-hot encoding format. This dictionary are used to decode it.\n",
        "    \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path,color_mode='grayscale', target_size=(64, 64)) # because the model can only receive 64x64 grayscale images, we need to convert it.\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=32)\n",
        "  print(fn)\n",
        "  print(classes)\n",
        "  result = np.argmax(classes)\n",
        "  print(np.amax(classes)*100) # print model's confidence level\n",
        "  \n",
        "  print(dictionary[result])# print the inference result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "OCR_original_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}